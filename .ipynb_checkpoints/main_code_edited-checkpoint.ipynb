{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84596d0b-c446-462c-8880-73fadef2d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "scan_pairs.py\n",
    "- Scan /workspace/cem_mitolab recursively.\n",
    "- Find \"images/\" and \"masks/\" sibling folders (case-insensitive).\n",
    "- Pair image <-> mask by relative path; fallback to stem matching with common-sense normalization.\n",
    "- Validate shape consistency; write report + pairs.txt + 16 overlay PNGs.\n",
    "\n",
    "Run:\n",
    "  python /workspace/scan_pairs.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "try:\n",
    "    import matplotlib\n",
    "    matplotlib.use(\"Agg\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    HAS_PLT = True\n",
    "except Exception:\n",
    "    HAS_PLT = False\n",
    "\n",
    "\n",
    "# ---------------------------- configurable ----------------------------\n",
    "ROOT = Path(os.environ.get(\"EMP_DIR\", \"/workspace/cem_mitolab\")).resolve()\n",
    "QA_DIR = Path(\"/workspace/qa\")\n",
    "IMG_DIR_RE = re.compile(r\"images?$\", re.I)   # images / image\n",
    "MSK_DIR_RE = re.compile(r\"masks?$\",  re.I)   # masks / mask\n",
    "EXTS = {\".tif\", \".tiff\", \".png\", \".jpg\", \".jpeg\"}\n",
    "\n",
    "# patterns to strip from stems when falling back to name-based matching\n",
    "STEM_CLEAN_RE = re.compile(r\"([_-](ch|loc|slice|z|t)?\\d+|[-_](\\d+))$\", re.I)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def is_image_file(p: Path) -> bool:\n",
    "    return p.is_file() and p.suffix.lower() in EXTS\n",
    "\n",
    "\n",
    "def find_sibling(dirpath: Path, pat: re.Pattern) -> Path | None:\n",
    "    \"\"\"\n",
    "    Find a sibling directory of dirpath whose name matches 'pat' (case-insensitive).\n",
    "    \"\"\"\n",
    "    parent = dirpath.parent\n",
    "    for d in parent.iterdir():\n",
    "        if d.is_dir() and pat.search(d.name):\n",
    "            return d\n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_stem(stem: str) -> str:\n",
    "    \"\"\"\n",
    "    Drop common trailing tokens like _ch0, -0001, -LOC-... etc (one pass).\n",
    "    \"\"\"\n",
    "    s = STEM_CLEAN_RE.sub(\"\", stem)\n",
    "    return s\n",
    "\n",
    "\n",
    "def try_mask_path(msk_root: Path, rel: Path) -> Path | None:\n",
    "    \"\"\"\n",
    "    Try multiple suffixes in order: .tiff -> .tif -> original\n",
    "    \"\"\"\n",
    "    cand = (msk_root / rel.with_suffix(\".tiff\"))\n",
    "    if cand.exists():\n",
    "        return cand\n",
    "    cand = (msk_root / rel.with_suffix(\".tif\"))\n",
    "    if cand.exists():\n",
    "        return cand\n",
    "    cand = (msk_root / rel)\n",
    "    if cand.exists():\n",
    "        return cand\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_stem_index(root: Path) -> Dict[str, Path]:\n",
    "    \"\"\"\n",
    "    Build a {normalized_stem: path} index under masks root (recursively).\n",
    "    If multiple files collide, keep the first one.\n",
    "    \"\"\"\n",
    "    idx: Dict[str, Path] = {}\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if is_image_file(p):\n",
    "            s = normalize_stem(p.stem).lower()\n",
    "            if s not in idx:\n",
    "                idx[s] = p\n",
    "    return idx\n",
    "\n",
    "\n",
    "def pair_images_masks(root: Path) -> Tuple[List[Tuple[str, str]], dict]:\n",
    "    \"\"\"\n",
    "    Walk root; for each 'images' dir, find sibling 'masks' dir, then pair files.\n",
    "    Return (pairs, stats_dict)\n",
    "    \"\"\"\n",
    "    pairs: List[Tuple[str, str]] = []\n",
    "    bad_missing_mask: List[str] = []\n",
    "    bad_read_error: List[str] = []\n",
    "    bad_size_mismatch: List[Tuple[str, str, tuple, tuple]] = []\n",
    "    size_hist: Dict[str, int] = {}\n",
    "\n",
    "    # find all candidate (images, masks) siblings\n",
    "    candidate_pairs: List[Tuple[Path, Path]] = []\n",
    "    for dirpath, dirnames, _ in os.walk(root):\n",
    "        dirpath = Path(dirpath)\n",
    "        # dirs in this level\n",
    "        imgs = [dirpath / d for d in dirnames if IMG_DIR_RE.search(d)]\n",
    "        msks = [dirpath / d for d in dirnames if MSK_DIR_RE.search(d)]\n",
    "        if not imgs or not msks:\n",
    "            continue\n",
    "        # choose the first match in this level\n",
    "        candidate_pairs.append((imgs[0], msks[0]))\n",
    "\n",
    "    # go through each (images_root, masks_root)\n",
    "    for img_root, msk_root in candidate_pairs:\n",
    "        stem_index = build_stem_index(msk_root)\n",
    "\n",
    "        for ip in img_root.rglob(\"*\"):\n",
    "            if not is_image_file(ip):\n",
    "                continue\n",
    "\n",
    "            # 1) match by relative path\n",
    "            rel = ip.relative_to(img_root)\n",
    "            mp = try_mask_path(msk_root, rel)\n",
    "\n",
    "            # 2) fallback: by normalized stem\n",
    "            if mp is None:\n",
    "                key = normalize_stem(ip.stem).lower()\n",
    "                mp = stem_index.get(key, None)\n",
    "\n",
    "            if mp is None or not mp.exists():\n",
    "                bad_missing_mask.append(str(ip))\n",
    "                continue\n",
    "\n",
    "            # read both and validate shape\n",
    "            try:\n",
    "                im = io.imread(str(ip))\n",
    "                mk = io.imread(str(mp))\n",
    "                if im.ndim == 3 and im.shape[-1] == 1:\n",
    "                    im = im[..., 0]\n",
    "                if mk.ndim == 3 and mk.shape[-1] == 1:\n",
    "                    mk = mk[..., 0]\n",
    "            except Exception:\n",
    "                bad_read_error.append(str(ip))\n",
    "                continue\n",
    "\n",
    "            if im.shape != mk.shape:\n",
    "                bad_size_mismatch.append((str(ip), str(mp), im.shape, mk.shape))\n",
    "                continue\n",
    "\n",
    "            key_shape = str(im.shape)\n",
    "            size_hist[key_shape] = size_hist.get(key_shape, 0) + 1\n",
    "            pairs.append((str(ip), str(mp)))\n",
    "\n",
    "    stats = {\n",
    "        \"root\": str(root),\n",
    "        \"num_sibling_levels\": len(candidate_pairs),\n",
    "        \"valid_pairs\": len(pairs),\n",
    "        \"size_histogram\": dict(sorted(size_hist.items(), key=lambda x: -x[1])),\n",
    "        \"bad_counts\": {\n",
    "            \"missing_mask\": len(bad_missing_mask),\n",
    "            \"read_error\": len(bad_read_error),\n",
    "            \"size_mismatch\": len(bad_size_mismatch),\n",
    "        },\n",
    "    }\n",
    "    # also save a little more detail (first few)\n",
    "    details = {\n",
    "        \"missing_mask_head\": bad_missing_mask[:10],\n",
    "        \"read_error_head\": bad_read_error[:10],\n",
    "        \"size_mismatch_head\": bad_size_mismatch[:5],\n",
    "    }\n",
    "    return pairs, {\"stats\": stats, \"details\": details}\n",
    "\n",
    "\n",
    "def save_overlays(pairs: List[Tuple[str, str]], outdir: Path, n: int = 16):\n",
    "    if not HAS_PLT or not pairs:\n",
    "        return\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    samp = random.sample(pairs, min(n, len(pairs)))\n",
    "    for i, (ip, mp) in enumerate(samp):\n",
    "        im = io.imread(ip); mk = io.imread(mp)\n",
    "        if im.ndim == 3 and im.shape[-1] == 1: im = im[..., 0]\n",
    "        if mk.ndim == 3 and mk.shape[-1] == 1: mk = mk[..., 0]\n",
    "        imf = im.astype(np.float32)\n",
    "        p1, p99 = np.percentile(imf, [1, 99])\n",
    "        if p99 > p1:\n",
    "            imf = np.clip((imf - p1) / (p99 - p1), 0, 1)\n",
    "        rgb = np.dstack([imf, (mk > 0).astype(np.float32), np.zeros_like(imf)])\n",
    "        plt.figure(figsize=(4, 4)); plt.axis(\"off\")\n",
    "        plt.imshow(rgb); plt.tight_layout(pad=0)\n",
    "        plt.savefig(outdir / f\"sample_{i:02d}.png\", dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"[scan] ROOT = {ROOT}\")\n",
    "    QA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pairs, info = pair_images_masks(ROOT)\n",
    "    # write pairs.txt\n",
    "    (QA_DIR / \"pairs.txt\").write_text(\n",
    "        \"\\n\".join([f\"{a}\\t{b}\" for a, b in pairs]), encoding=\"utf-8\"\n",
    "    )\n",
    "    # write report\n",
    "    with open(QA_DIR / \"report-smart.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(info[\"stats\"], f, indent=2)\n",
    "    with open(QA_DIR / \"report-smart-details.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(info, f, indent=2)\n",
    "\n",
    "    print(json.dumps(info[\"stats\"], indent=2))\n",
    "    # overlays\n",
    "    save_overlays(pairs, QA_DIR, n=16)\n",
    "    if pairs:\n",
    "        print(f\"[scan] Wrote {len(pairs)} pairs to {QA_DIR/'pairs.txt'} and overlays to {QA_DIR}\")\n",
    "    else:\n",
    "        print(\"[scan] No valid pairs found. Check details JSON and directory naming (images/ vs masks/).\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f0094-90ed-40af-a2e3-7efa3fd77534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "tile_pairs.py\n",
    "Cut paired (image, mask) files into MoDL-style 512×512 tiles.\n",
    "\n",
    "Input:\n",
    "  - a pairs list file, each line: <image_path>\\t<mask_path>\n",
    "    (we already generated /workspace/qa/pairs.txt via scan_pairs.py)\n",
    "Output:\n",
    "  - tiled image pngs to out_img_dir\n",
    "  - tiled mask  pngs to out_msk_dir\n",
    "  - a summary json\n",
    "\n",
    "Usage (inside the container):\n",
    "  python /workspace/tile_pairs.py \\\n",
    "      --pairs /workspace/qa/pairs.txt \\\n",
    "      --out-img /workspace/deform/train \\\n",
    "      --out-msk /workspace/deform/label \\\n",
    "      --tile 512 --stride 512 --keep-bg false\n",
    "\n",
    "Note:\n",
    "  - Mask is binarized as (mask > 0).\n",
    "  - Image is percentile (1,99) normalized to uint8.\n",
    "  - Non-multiple sizes are reflect-padded to the next grid.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    tqdm = lambda x, **k: x  # fallback: no progress bar\n",
    "\n",
    "\n",
    "def to_uint8_percentile(im: np.ndarray, p1: float = 1.0, p99: float = 99.0) -> np.ndarray:\n",
    "    \"\"\"Normalize image by (p1, p99) percentiles -> uint8.\"\"\"\n",
    "    imf = im.astype(np.float32)\n",
    "    lo, hi = np.percentile(imf, [p1, p99])\n",
    "    if hi > lo:\n",
    "        imf = np.clip((imf - lo) / (hi - lo), 0, 1)\n",
    "    else:\n",
    "        # fallback to min-max\n",
    "        lo, hi = imf.min(), imf.max()\n",
    "        if hi > lo:\n",
    "            imf = (imf - lo) / (hi - lo)\n",
    "        else:\n",
    "            imf = np.zeros_like(imf, dtype=np.float32)\n",
    "    return (imf * 255.0 + 0.5).astype(np.uint8)\n",
    "\n",
    "\n",
    "def reflect_pad_to_grid(im: np.ndarray, tile: int) -> np.ndarray:\n",
    "    \"\"\"Pad with reflect to the next multiple of tile.\"\"\"\n",
    "    H, W = im.shape[:2]\n",
    "    Hn = int(ceil(H / tile) * tile)\n",
    "    Wn = int(ceil(W / tile) * tile)\n",
    "    if Hn == H and Wn == W:\n",
    "        return im\n",
    "    pad_h = Hn - H\n",
    "    pad_w = Wn - W\n",
    "    if im.ndim == 2:\n",
    "        return np.pad(im, ((0, pad_h), (0, pad_w)), mode=\"reflect\")\n",
    "    else:  # (H, W, C)\n",
    "        return np.pad(im, ((0, pad_h), (0, pad_w), (0, 0)), mode=\"reflect\")\n",
    "\n",
    "\n",
    "def iter_tiles(im: np.ndarray, mk: np.ndarray, tile: int, stride: int, keep_bg: bool):\n",
    "    H, W = im.shape[:2]\n",
    "    for y in range(0, H - tile + 1, stride):\n",
    "        for x in range(0, W - tile + 1, stride):\n",
    "            imt = im[y : y + tile, x : x + tile]\n",
    "            mkt = mk[y : y + tile, x : x + tile]\n",
    "            if not keep_bg and mkt.max() == 0:\n",
    "                continue\n",
    "            yield x, y, imt, mkt\n",
    "\n",
    "\n",
    "def load_pair(ip: Path, mp: Path) -> Tuple[np.ndarray, np.ndarray] | None:\n",
    "    \"\"\"Read image & mask; squeeze singleton channel; validate shape.\"\"\"\n",
    "    try:\n",
    "        im = io.imread(str(ip))\n",
    "        mk = io.imread(str(mp))\n",
    "        # squeeze trailing singleton channel if present\n",
    "        if im.ndim == 3 and im.shape[-1] == 1:\n",
    "            im = im[..., 0]\n",
    "        if mk.ndim == 3 and mk.shape[-1] == 1:\n",
    "            mk = mk[..., 0]\n",
    "        if im.shape != mk.shape:\n",
    "            return None\n",
    "        return im, mk\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Cut paired images/masks into MoDL tiles.\")\n",
    "    parser.add_argument(\"--pairs\", type=str, required=True,\n",
    "                        help=\"pairs.txt generated by scan_pairs.py\")\n",
    "    parser.add_argument(\"--out-img\", type=str, default=\"/workspace/deform/train\",\n",
    "                        help=\"output dir for image tiles\")\n",
    "    parser.add_argument(\"--out-msk\", type=str, default=\"/workspace/deform/label\",\n",
    "                        help=\"output dir for mask tiles\")\n",
    "    parser.add_argument(\"--tile\", type=int, default=512, help=\"tile size\")\n",
    "    parser.add_argument(\"--stride\", type=int, default=512, help=\"stride\")\n",
    "    parser.add_argument(\"--keep-bg\", type=str, default=\"false\",\n",
    "                        help=\"keep background-only tiles? (true/false)\")\n",
    "    parser.add_argument(\"--limit\", type=int, default=0,\n",
    "                        help=\"optional: only process first N pairs (for quick test)\")\n",
    "    parser.add_argument(\"--summary\", type=str, default=\"/workspace/qa/tiling_report.json\",\n",
    "                        help=\"where to write summary json\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    keep_bg = str(args.keep_bg).lower() in {\"1\", \"true\", \"yes\", \"y\"}\n",
    "\n",
    "    pairs_file = Path(args.pairs).resolve()\n",
    "    out_img = Path(args.out_img).resolve()\n",
    "    out_msk = Path(args.out_msk).resolve()\n",
    "    out_img.mkdir(parents=True, exist_ok=True)\n",
    "    out_msk.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not pairs_file.exists():\n",
    "        raise FileNotFoundError(f\"pairs file not found: {pairs_file}\")\n",
    "\n",
    "    # read lines\n",
    "    lines = [ln.strip() for ln in pairs_file.read_text(encoding=\"utf-8\").splitlines() if ln.strip()]\n",
    "    if args.limit and args.limit > 0:\n",
    "        lines = lines[: args.limit]\n",
    "\n",
    "    total_pairs = len(lines)\n",
    "    n_tiles = 0\n",
    "    n_drop = 0\n",
    "    n_readerr = 0\n",
    "    n_mismatch = 0\n",
    "\n",
    "    for ln in tqdm(lines, desc=\"tiling\"):\n",
    "        if \"\\t\" not in ln:\n",
    "            continue\n",
    "        ip_str, mp_str = ln.split(\"\\t\", 1)\n",
    "        ip, mp = Path(ip_str), Path(mp_str)\n",
    "\n",
    "        pair = load_pair(ip, mp)\n",
    "        if pair is None:\n",
    "            # try to distinguish mismatch vs readerr (best-effort)\n",
    "            try:\n",
    "                _im = io.imread(str(ip))\n",
    "                _mk = io.imread(str(mp))\n",
    "                if _im.ndim == 3 and _im.shape[-1] == 1:\n",
    "                    _im = _im[..., 0]\n",
    "                if _mk.ndim == 3 and _mk.shape[-1] == 1:\n",
    "                    _mk = _mk[..., 0]\n",
    "                if _im.shape != _mk.shape:\n",
    "                    n_mismatch += 1\n",
    "                else:\n",
    "                    n_readerr += 1\n",
    "            except Exception:\n",
    "                n_readerr += 1\n",
    "            continue\n",
    "\n",
    "        im, mk = pair\n",
    "        # normalize & binarize\n",
    "        im8 = to_uint8_percentile(im)\n",
    "        mkb = (mk > 0).astype(np.uint8) * 255\n",
    "\n",
    "        # pad to grid\n",
    "        im8 = reflect_pad_to_grid(im8, args.tile)\n",
    "        mkb = reflect_pad_to_grid(mkb, args.tile)\n",
    "\n",
    "        base = ip.stem  # file stem as base name\n",
    "        for x, y, imt, mkt in iter_tiles(im8, mkb, args.tile, args.stride, keep_bg):\n",
    "            name = f\"em11037_{base}_x{x}_y{y}.png\"\n",
    "            io.imsave(str(out_img / name), imt, check_contrast=False)\n",
    "            io.imsave(str(out_msk / name), mkt, check_contrast=False)\n",
    "            n_tiles += 1\n",
    "\n",
    "    summary = {\n",
    "        \"pairs_file\": str(pairs_file),\n",
    "        \"total_pairs_read\": total_pairs,\n",
    "        \"processed_pairs\": total_pairs - (n_readerr + n_mismatch),\n",
    "        \"read_errors\": n_readerr,\n",
    "        \"shape_mismatch\": n_mismatch,\n",
    "        \"tiles_written\": n_tiles,\n",
    "        \"out_img\": str(out_img),\n",
    "        \"out_msk\": str(out_msk),\n",
    "        \"tile\": args.tile,\n",
    "        \"stride\": args.stride,\n",
    "        \"keep_bg\": keep_bg,\n",
    "    }\n",
    "    Path(args.summary).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(args.summary, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(json.dumps(summary, indent=2))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80928f4-5d3c-4477-b9b7-0473c5106e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_npy_80_10_10.py\n",
    "# 读取 npydata/imgs_train.npy & imgs_mask_train.npy\n",
    "# 按 0.8 / 0.1 / 0.1 随机划分 train / val / test\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(__file__).resolve().parent\n",
    "NPYDIR = ROOT / \"npydata\"\n",
    "\n",
    "X_path = NPYDIR / \"imgs_train.npy\"\n",
    "Y_path = NPYDIR / \"imgs_mask_train.npy\"\n",
    "\n",
    "print(\"[load]\", X_path)\n",
    "print(\"[load]\", Y_path)\n",
    "X = np.load(X_path)\n",
    "Y = np.load(Y_path)\n",
    "\n",
    "assert X.shape[0] == Y.shape[0], \"X 和 Y 的样本数量不一致！\"\n",
    "N = X.shape[0]\n",
    "print(f\"[info] 总样本数 N = {N}\")\n",
    "\n",
    "# 为了可复现，可以固定随机种子\n",
    "rng = np.random.default_rng(seed=42)\n",
    "idx = rng.permutation(N)\n",
    "\n",
    "n_train = int(N * 0.8)\n",
    "n_val   = int(N * 0.1)\n",
    "n_test  = N - n_train - n_val   # 剩下的都给 test，保证总数对得上\n",
    "\n",
    "i_train = idx[:n_train]\n",
    "i_val   = idx[n_train:n_train + n_val]\n",
    "i_test  = idx[n_train + n_val:]\n",
    "\n",
    "splits = {\n",
    "    \"train\": i_train,\n",
    "    \"val\":   i_val,\n",
    "    \"test\":  i_test,\n",
    "}\n",
    "\n",
    "for name, inds in splits.items():\n",
    "    X_split = X[inds]\n",
    "    Y_split = Y[inds]\n",
    "    np.save(NPYDIR / f\"imgs_{name}.npy\", X_split)\n",
    "    np.save(NPYDIR / f\"masks_{name}.npy\", Y_split)\n",
    "    print(f\"[save] imgs_{name}.npy 形状: {X_split.shape}\")\n",
    "    print(f\"[save] masks_{name}.npy 形状: {Y_split.shape}\")\n",
    "\n",
    "print(\"[done] 划分完成：train/val/test =\",\n",
    "      splits[\"train\"].size, splits[\"val\"].size, splits[\"test\"].size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522af0ba-c546-4c65-8259-bbf3718d8981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement data_load (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for data_load\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install data_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9074f417-f9f8-4028-a0f0-55adc226dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../npydata/imgs_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 250\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    249\u001b[0m    myunet \u001b[38;5;241m=\u001b[39m myUnet()\n\u001b[0;32m--> 250\u001b[0m    \u001b[43mmyunet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 123\u001b[0m, in \u001b[0;36mmyUnet.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m  \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# ------- 读入 npy -------\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m  imgs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../npydata/imgs_train.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m  masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../npydata/imgs_mask_train.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m  \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal samples (full):\u001b[39m\u001b[38;5;124m\"\u001b[39m, imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../npydata/imgs_train.npy'"
     ]
    }
   ],
   "source": [
    "#train.py code\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, UpSampling2D,\n",
    "    Dropout, BatchNormalization, concatenate,\n",
    "    Conv2DTranspose, Concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from MoDL_seg.data_load import *\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "class myUnet(object):\n",
    "   def __init__(self, img_rows = 512, img_cols = 512):\n",
    "      self.img_rows = img_rows\n",
    "      self.img_cols = img_cols\n",
    "\n",
    "   def load_data(self):\n",
    "      mydata = DataProcess(self.img_rows, self.img_cols)\n",
    "      imgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "      return imgs_train, imgs_mask_train\n",
    "\n",
    "   def get_unet(self):\n",
    "    \"\"\"\n",
    "    UNet architecture from scratch with encoder-decoder structure\n",
    "    Same number of layers as the original implementation\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input((self.img_rows, self.img_cols, 1))\n",
    "    \n",
    "    # ========== ENCODER PATH (Contracting) ==========\n",
    "    \n",
    "    # Encoder Block 1: 64 filters\n",
    "    e1_conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    e1_conv2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(e1_conv1)\n",
    "    e1_pool = MaxPooling2D(pool_size=(2, 2))(e1_conv2)\n",
    "    \n",
    "    # Encoder Block 2: 128 filters\n",
    "    e2_conv1 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(e1_pool)\n",
    "    e2_conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(e2_conv1)\n",
    "    e2_pool = MaxPooling2D(pool_size=(2, 2))(e2_conv2)\n",
    "    \n",
    "    # Encoder Block 3: 256 filters\n",
    "    e3_conv1 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(e2_pool)\n",
    "    e3_conv2 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(e3_conv1)\n",
    "    e3_pool = MaxPooling2D(pool_size=(2, 2))(e3_conv2)\n",
    "    \n",
    "    # Encoder Block 4: 512 filters with dropout\n",
    "    e4_conv1 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(e3_pool)\n",
    "    e4_conv2 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(e4_conv1)\n",
    "    e4_drop = Dropout(0.5)(e4_conv2)\n",
    "    e4_pool = MaxPooling2D(pool_size=(2, 2))(e4_drop)\n",
    "    \n",
    "    # ========== BOTTLENECK ==========\n",
    "    \n",
    "    # Bottleneck Block: 1024 filters with dropout\n",
    "    bottleneck_conv1 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(e4_pool)\n",
    "    bottleneck_conv2 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(bottleneck_conv1)\n",
    "    bottleneck_drop = Dropout(0.5)(bottleneck_conv2)\n",
    "    \n",
    "    # ========== DECODER PATH (Expanding) ==========\n",
    "    \n",
    "    # Decoder Block 1: 512 filters\n",
    "    d1_upsample = UpSampling2D(size=(2, 2))(bottleneck_drop)\n",
    "    d1_transpose = Conv2DTranspose(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(d1_upsample)\n",
    "    d1_merge = Concatenate(axis=3)([e4_drop, d1_transpose])\n",
    "    d1_conv1 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d1_merge)\n",
    "    d1_conv2 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d1_conv1)\n",
    "    \n",
    "    # Decoder Block 2: 256 filters\n",
    "    d2_upsample = UpSampling2D(size=(2, 2))(d1_conv2)\n",
    "    d2_transpose = Conv2DTranspose(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(d2_upsample)\n",
    "    d2_merge = Concatenate(axis=3)([e3_conv2, d2_transpose])\n",
    "    d2_conv1 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d2_merge)\n",
    "    d2_conv2 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d2_conv1)\n",
    "    \n",
    "    # Decoder Block 3: 128 filters\n",
    "    d3_upsample = UpSampling2D(size=(2, 2))(d2_conv2)\n",
    "    d3_transpose = Conv2DTranspose(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(d3_upsample)\n",
    "    d3_merge = Concatenate(axis=3)([e2_conv2, d3_transpose])\n",
    "    d3_conv1 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d3_merge)\n",
    "    d3_conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d3_conv1)\n",
    "    \n",
    "    # Decoder Block 4: 64 filters\n",
    "    d4_upsample = UpSampling2D(size=(2, 2))(d3_conv2)\n",
    "    d4_transpose = Conv2DTranspose(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(d4_upsample)\n",
    "    d4_merge = Concatenate(axis=3)([e1_conv2, d4_transpose])\n",
    "    d4_conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d4_merge)\n",
    "    d4_conv2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d4_conv1)\n",
    "    \n",
    "    # ========== OUTPUT LAYER ==========\n",
    "    \n",
    "    # Additional conv layer with 2 filters (matching original)\n",
    "    output_conv1 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d4_conv2)\n",
    "    \n",
    "    # Final output layer: 1 filter with sigmoid activation\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(output_conv1)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    " \n",
    "\n",
    "   def train(self):\n",
    "         print(\"loading data\")\n",
    "\n",
    "        # ------- 读入 npy -------\n",
    "         imgs = np.load(\"../npydata/imgs_train.npy\").astype(\"float32\")\n",
    "         masks = np.load(\"../npydata/imgs_mask_train.npy\").astype(\"float32\")\n",
    "         print(\"total samples (full):\", imgs.shape[0])\n",
    "\n",
    "        # ------- 限制最多使用一部分数据，避免一次性太大 -------\n",
    "         MAX_SAMPLES = 6000  # 可以以后再调大 / 调小\n",
    "         N = imgs.shape[0]\n",
    "         if N > MAX_SAMPLES:\n",
    "            rng = np.random.default_rng(seed=42)\n",
    "            idx = rng.choice(N, size=MAX_SAMPLES, replace=False)\n",
    "            imgs = imgs[idx]\n",
    "            masks = masks[idx]\n",
    "            print(f\"subsampled to {MAX_SAMPLES} samples for GPU training\")\n",
    "         else:\n",
    "            print(\"use all samples for GPU training\")\n",
    "\n",
    "        # ------- 归一化 + 类型降为 float16（减少显存占用） -------\n",
    "         imgs = imgs.astype(\"float16\")\n",
    "         masks = masks.astype(\"float16\")\n",
    "\n",
    "         imgs /= 255.0\n",
    "         mean = imgs.mean(axis=0, dtype=\"float32\")   # 用 float32 计算均值更稳\n",
    "         imgs = imgs - mean.astype(\"float16\")\n",
    "\n",
    "         masks /= 255.0\n",
    "         masks[masks > 0.5] = 1.0\n",
    "         masks[masks <= 0.5] = 0.0\n",
    "\n",
    "         print(\"after subsample:\", imgs.shape[0])\n",
    "\n",
    "        # ------- 划分训练集 / 验证集（0.8 / 0.2） -------\n",
    "         N = imgs.shape[0]\n",
    "         val_ratio = 0.2\n",
    "         val_size = int(N * val_ratio)\n",
    "\n",
    "         rng = np.random.default_rng(seed=123)\n",
    "         indices = rng.permutation(N)\n",
    "\n",
    "         val_idx = indices[:val_size]\n",
    "         train_idx = indices[val_size:]\n",
    "\n",
    "         X_train = imgs[train_idx]\n",
    "         Y_train = masks[train_idx]\n",
    "         X_val   = imgs[val_idx]\n",
    "         Y_val   = masks[val_idx]\n",
    "\n",
    "         print(f\"train: {X_train.shape[0]}  val: {X_val.shape[0]}\")\n",
    "\n",
    "        # ------- 用 tf.data.Dataset 按 batch 喂 GPU -------\n",
    "         BATCH_SIZE   = 2   # 显存安全起见先用 1，跑通后可以尝试改成 2\n",
    "         TOTAL_EPOCHS = 30 # 本次只跑 10 个 epoch\n",
    "\n",
    "         train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "         train_ds = train_ds.shuffle(buffer_size=len(X_train))\n",
    "         train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "         val_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "         val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        # ------- 每次都从头建一个新模型，不继承旧的 -------\n",
    "         print(\"building a fresh model...\")\n",
    "         model = self.get_unet()\n",
    "         print(\"got unet\")\n",
    "\n",
    "         model.compile(\n",
    "            optimizer=Adam(learning_rate=1e-4),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "         )\n",
    "\n",
    "         CHECKPOINT_PATH = \"../model/U-RNet+_gpu_10ep.keras\"\n",
    "         model_checkpoint = ModelCheckpoint(\n",
    "            CHECKPOINT_PATH,\n",
    "            monitor=\"val_loss\",   # 用验证集损失挑 best\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "         )\n",
    "\n",
    "         starttrain = datetime.datetime.now()\n",
    "         print(\"Fitting model...\")\n",
    "\n",
    "         history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=TOTAL_EPOCHS,\n",
    "            verbose=1,\n",
    "            validation_data=val_ds,\n",
    "            callbacks=[model_checkpoint],\n",
    "         )\n",
    "\n",
    "         endtrain = datetime.datetime.now()\n",
    "         print(\"train time: %s seconds\" % (endtrain - starttrain))\n",
    "\n",
    "        # ------- 画 Accuracy / Loss 曲线 -------\n",
    "         acc      = history.history[\"accuracy\"]\n",
    "         val_acc  = history.history[\"val_accuracy\"]\n",
    "         loss     = history.history[\"loss\"]\n",
    "         val_loss = history.history[\"val_loss\"]\n",
    "         epochs   = range(len(acc))\n",
    "\n",
    "         plt.figure()\n",
    "         plt.plot(epochs, acc, \"b\", label=\"training accuracy\")\n",
    "         plt.plot(epochs, val_acc, \":r\", label=\"validation accuracy\")\n",
    "         plt.title(\"Accuracy\")\n",
    "         plt.xlabel(\"Epoch\")\n",
    "         plt.ylabel(\"Accuracy\")\n",
    "         plt.legend()\n",
    "         plt.savefig(\"../model/Accuracy.png\")\n",
    "\n",
    "         plt.figure()\n",
    "         plt.plot(epochs, loss, \"b\", label=\"training loss\")\n",
    "         plt.plot(epochs, val_loss, \":r\", label=\"validation loss\")\n",
    "         plt.title(\"Loss\")\n",
    "         plt.xlabel(\"Epoch\")\n",
    "         plt.ylabel(\"Loss\")\n",
    "         plt.legend()\n",
    "         plt.savefig(\"../model/Loss.png\")\n",
    "\n",
    "         plt.show()\n",
    "\n",
    "         with open(\"../model/unet.txt\", \"wt\") as ft:\n",
    "            ft.write(\"loss: %.6s\\n\" % (loss[-1]))\n",
    "            ft.write(\"accuracy: %.6s\\n\" % (acc[-1]))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "   myunet = myUnet()\n",
    "   myunet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b266b4c-d7d1-46f1-8620-ddb6b8cb521c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
