{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8899e53-8299-48de-aa29-f579d886ca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 23:25:07.148705: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UNIFIED SEGMENTATION & DENSITY CLASSIFICATION MODEL\n",
      "============================================================\n",
      "\n",
      "Initializing unified model...\n",
      "Processing image...\n",
      "\n",
      "Results:\n",
      "  Signal mask shape: (512, 512)\n",
      "  Density classification shape: (512, 512)\n",
      "  Signal pixels: 17492\n",
      "  Density classes found: [0 1 2 3]\n",
      "\n",
      "Statistics:\n",
      "  Thresholds: [30.0, 50.0]\n",
      "  Class 1: 9216 pixels\n",
      "    Mean intensity: 30.0 ± 0.0\n",
      "  Class 2: 2500 pixels\n",
      "    Mean intensity: 46.9 ± 7.2\n",
      "  Class 3: 5776 pixels\n",
      "    Mean intensity: 65.9 ± 11.0\n",
      "\n",
      "============================================================\n",
      "Usage Examples:\n",
      "============================================================\n",
      "  # Process numpy array\n",
      "  model = UnifiedSegmentationDensityModel(n_density_classes=3)\n",
      "  signal_mask, density_class, stats = model.process(image)\n",
      "\n",
      "  # Process image file\n",
      "  model.process_image('input.tif', 'signal.tif', 'density.tif', visualize=True)\n",
      "\n",
      "  # Process directory\n",
      "  model.process_directory('input_dir/', 'output_dir/')\n",
      "\n",
      "  # Deep learning model (requires training)\n",
      "  unet_model = UnifiedSegmentationDensityUNet(n_density_classes=3)\n",
      "  unet_model.build_model()\n",
      "  # Train model...\n",
      "  signal_mask, density_class = unet_model.process(image)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unified Segmentation and Density Classification Model - Standalone Version\n",
    "\n",
    "This file contains the unified models with all dependencies included.\n",
    "Performs both signal-background segmentation and intensity density classification in one step.\n",
    "\n",
    "Usage:\n",
    "    from unified_model_standalone import UnifiedSegmentationDensityModel\n",
    "    \n",
    "    model = UnifiedSegmentationDensityModel(n_density_classes=3)\n",
    "    signal_mask, density_class, stats = model.process(image)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import Tuple, Optional, Union, Dict\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning imports (optional, for U-Net model)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.layers import (\n",
    "        Input, Conv2D, MaxPooling2D, UpSampling2D,\n",
    "        Concatenate, Conv2DTranspose, BatchNormalization\n",
    "    )\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    HAS_TF = True\n",
    "except ImportError:\n",
    "    HAS_TF = False\n",
    "    print(\"Warning: TensorFlow not available. U-Net model will not work.\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DEPENDENCY CLASSES\n",
    "# ============================================================================\n",
    "\n",
    "class InverseThresholdModel:\n",
    "    \"\"\"\n",
    "    Simple thresholding-based model for separating dark signal from bright background.\n",
    "    Used internally by the unified model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, method='otsu', blur_size=5, adaptive_block_size=11, adaptive_c=2):\n",
    "        \"\"\"\n",
    "        Initialize thresholding model\n",
    "        \n",
    "        Args:\n",
    "            method: 'otsu', 'adaptive', or 'percentile'\n",
    "            blur_size: Gaussian blur kernel size (odd number, 0 to disable)\n",
    "            adaptive_block_size: Block size for adaptive thresholding (odd number)\n",
    "            adaptive_c: Constant subtracted from mean in adaptive thresholding\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.blur_size = blur_size\n",
    "        self.adaptive_block_size = adaptive_block_size\n",
    "        self.adaptive_c = adaptive_c\n",
    "    \n",
    "    def preprocess(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Preprocess image: ensure uint8, apply blur if needed\"\"\"\n",
    "        # Convert to uint8 if needed\n",
    "        if image.dtype != np.uint8:\n",
    "            if image.max() <= 1.0:\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "            else:\n",
    "                image = image.astype(np.uint8)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        if self.blur_size > 0:\n",
    "            image = cv2.GaussianBlur(image, (self.blur_size, self.blur_size), 0)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def segment(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Segment image: dark regions (signal) vs bright regions (background)\n",
    "        \n",
    "        Args:\n",
    "            image: Input grayscale image (H, W) or (H, W, C)\n",
    "            \n",
    "        Returns:\n",
    "            Binary mask: 1 = signal (dark), 0 = background (bright)\n",
    "        \"\"\"\n",
    "        # Handle multi-channel images\n",
    "        if len(image.shape) == 3:\n",
    "            if image.shape[2] == 1:\n",
    "                image = image[:, :, 0]\n",
    "            else:\n",
    "                image = np.mean(image, axis=2)\n",
    "        \n",
    "        # Preprocess\n",
    "        image = self.preprocess(image)\n",
    "        \n",
    "        # Apply thresholding method\n",
    "        if self.method == 'otsu':\n",
    "            # Otsu's method: automatically finds optimal threshold\n",
    "            threshold_value, binary = cv2.threshold(\n",
    "                image, 0, 1, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "            )\n",
    "            # THRESH_BINARY_INV: dark pixels (low intensity) become 1\n",
    "            \n",
    "        elif self.method == 'adaptive':\n",
    "            # Adaptive thresholding: handles varying illumination\n",
    "            binary = cv2.adaptiveThreshold(\n",
    "                image, 1, \n",
    "                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                cv2.THRESH_BINARY_INV,\n",
    "                self.adaptive_block_size,\n",
    "                self.adaptive_c\n",
    "            )\n",
    "            \n",
    "        elif self.method == 'percentile':\n",
    "            # Percentile-based thresholding\n",
    "            threshold_value = np.percentile(image, 30)  # Bottom 30% = signal\n",
    "            binary = (image < threshold_value).astype(np.uint8)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {self.method}\")\n",
    "        \n",
    "        return binary.astype(np.uint8)\n",
    "\n",
    "\n",
    "class IntensityDensityClassifier:\n",
    "    \"\"\"\n",
    "    Classifies different intensity densities within low-intensity signal regions.\n",
    "    Used internally by the unified model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_classes=3, method='percentile', blur_size=3):\n",
    "        \"\"\"\n",
    "        Initialize density classifier\n",
    "        \n",
    "        Args:\n",
    "            n_classes: Number of density classes (e.g., 3 = low/medium/high density)\n",
    "            method: 'percentile', 'kmeans', or 'equal_width'\n",
    "            blur_size: Gaussian blur kernel size for smoothing (odd number, 0 to disable)\n",
    "        \"\"\"\n",
    "        self.n_classes = n_classes\n",
    "        self.method = method\n",
    "        self.blur_size = blur_size\n",
    "        self.thresholds = None\n",
    "    \n",
    "    def preprocess(self, image: np.ndarray, signal_mask: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Preprocess image and mask: extract signal regions only\"\"\"\n",
    "        # Ensure uint8\n",
    "        if image.dtype != np.uint8:\n",
    "            if image.max() <= 1.0:\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "            else:\n",
    "                image = image.astype(np.uint8)\n",
    "        \n",
    "        # Ensure binary mask\n",
    "        if signal_mask.dtype != np.uint8:\n",
    "            signal_mask = (signal_mask > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # Apply blur to reduce noise\n",
    "        if self.blur_size > 0:\n",
    "            image = cv2.GaussianBlur(image, (self.blur_size, self.blur_size), 0)\n",
    "        \n",
    "        return image, signal_mask\n",
    "    \n",
    "    def compute_thresholds(self, image: np.ndarray, signal_mask: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute intensity thresholds for density classification\"\"\"\n",
    "        # Extract signal region intensities\n",
    "        signal_intensities = image[signal_mask == 1]\n",
    "        \n",
    "        if len(signal_intensities) == 0:\n",
    "            # No signal regions, return default thresholds\n",
    "            return np.linspace(0, 255, self.n_classes + 1)[1:-1]\n",
    "        \n",
    "        if self.method == 'percentile':\n",
    "            # Use percentiles to divide into equal-sized groups\n",
    "            percentiles = np.linspace(0, 100, self.n_classes + 1)[1:-1]\n",
    "            thresholds = np.percentile(signal_intensities, percentiles)\n",
    "            \n",
    "        elif self.method == 'equal_width':\n",
    "            # Divide intensity range into equal-width bins\n",
    "            min_intensity = signal_intensities.min()\n",
    "            max_intensity = signal_intensities.max()\n",
    "            thresholds = np.linspace(min_intensity, max_intensity, self.n_classes + 1)[1:-1]\n",
    "            \n",
    "        elif self.method == 'kmeans':\n",
    "            # Use k-means clustering (simple implementation)\n",
    "            try:\n",
    "                from sklearn.cluster import KMeans\n",
    "                intensities_reshaped = signal_intensities.reshape(-1, 1)\n",
    "                kmeans = KMeans(n_clusters=self.n_classes, random_state=42, n_init=10)\n",
    "                kmeans.fit(intensities_reshaped)\n",
    "                centers = np.sort(kmeans.cluster_centers_.flatten())\n",
    "                thresholds = (centers[:-1] + centers[1:]) / 2\n",
    "            except ImportError:\n",
    "                raise ImportError(\"scikit-learn required for kmeans method. Install with: pip install scikit-learn\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {self.method}\")\n",
    "        \n",
    "        return thresholds\n",
    "    \n",
    "    def classify(self, image: np.ndarray, signal_mask: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Classify signal regions into different density classes\n",
    "        \n",
    "        Args:\n",
    "            image: Original grayscale image (H, W) or (H, W, C)\n",
    "            signal_mask: Binary mask where 1 = signal regions (H, W)\n",
    "            \n",
    "        Returns:\n",
    "            Multi-class mask: 0 = background, 1..n_classes = density classes\n",
    "            (1 = lowest density, n_classes = highest density)\n",
    "        \"\"\"\n",
    "        # Handle multi-channel images\n",
    "        if len(image.shape) == 3:\n",
    "            if image.shape[2] == 1:\n",
    "                image = image[:, :, 0]\n",
    "            else:\n",
    "                image = np.mean(image, axis=2)\n",
    "        \n",
    "        # Preprocess\n",
    "        image, signal_mask = self.preprocess(image, signal_mask)\n",
    "        \n",
    "        # Compute thresholds\n",
    "        thresholds = self.compute_thresholds(image, signal_mask)\n",
    "        self.thresholds = thresholds\n",
    "        \n",
    "        # Initialize classification mask (0 = background)\n",
    "        classification = np.zeros_like(image, dtype=np.uint8)\n",
    "        \n",
    "        # Classify signal regions\n",
    "        signal_pixels = signal_mask == 1\n",
    "        \n",
    "        # Assign classes based on thresholds\n",
    "        # Class 1: lowest density (darkest)\n",
    "        classification[signal_pixels & (image <= thresholds[0])] = 1\n",
    "        \n",
    "        # Middle classes\n",
    "        for i in range(1, len(thresholds)):\n",
    "            classification[signal_pixels & (image > thresholds[i-1]) & (image <= thresholds[i])] = i + 1\n",
    "        \n",
    "        # Class n_classes: highest density (brightest signal)\n",
    "        classification[signal_pixels & (image > thresholds[-1])] = self.n_classes\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    def classify_with_stats(self, image: np.ndarray, signal_mask: np.ndarray) -> Tuple[np.ndarray, dict]:\n",
    "        \"\"\"\n",
    "        Classify and return statistics\n",
    "        \n",
    "        Args:\n",
    "            image: Original grayscale image\n",
    "            signal_mask: Binary mask where 1 = signal regions\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (classification_mask, statistics_dict)\n",
    "        \"\"\"\n",
    "        classification = self.classify(image, signal_mask)\n",
    "        \n",
    "        # Compute statistics for each class\n",
    "        stats = {\n",
    "            'n_classes': self.n_classes,\n",
    "            'thresholds': self.thresholds.tolist() if self.thresholds is not None else None,\n",
    "            'class_counts': {},\n",
    "            'class_intensities': {}\n",
    "        }\n",
    "        \n",
    "        for class_id in range(1, self.n_classes + 1):\n",
    "            class_mask = classification == class_id\n",
    "            stats['class_counts'][class_id] = int(np.sum(class_mask))\n",
    "            \n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_intensities = image[class_mask]\n",
    "                stats['class_intensities'][class_id] = {\n",
    "                    'mean': float(np.mean(class_intensities)),\n",
    "                    'std': float(np.std(class_intensities)),\n",
    "                    'min': int(np.min(class_intensities)),\n",
    "                    'max': int(np.max(class_intensities))\n",
    "                }\n",
    "        \n",
    "        return classification, stats\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UNIFIED MODELS\n",
    "# ============================================================================\n",
    "\n",
    "class UnifiedSegmentationDensityModel:\n",
    "    \"\"\"\n",
    "    Unified model that performs both segmentation and density classification in one step.\n",
    "    Combines signal-background separation with intensity density classification.\n",
    "    \n",
    "    This is a thresholding-based model that requires no training.\n",
    "    \n",
    "    Example:\n",
    "        model = UnifiedSegmentationDensityModel(n_density_classes=3)\n",
    "        signal_mask, density_class, stats = model.process(image)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 seg_method='otsu',\n",
    "                 density_method='percentile',\n",
    "                 n_density_classes=3,\n",
    "                 blur_size=5,\n",
    "                 adaptive_block_size=11,\n",
    "                 adaptive_c=2):\n",
    "        \"\"\"\n",
    "        Initialize unified model\n",
    "        \n",
    "        Args:\n",
    "            seg_method: Segmentation method ('otsu', 'adaptive', 'percentile')\n",
    "            density_method: Density classification method ('percentile', 'equal_width', 'kmeans')\n",
    "            n_density_classes: Number of density classes (default 3)\n",
    "            blur_size: Gaussian blur kernel size\n",
    "            adaptive_block_size: Block size for adaptive thresholding\n",
    "            adaptive_c: Constant for adaptive thresholding\n",
    "        \"\"\"\n",
    "        # Initialize segmentation model\n",
    "        self.seg_model = InverseThresholdModel(\n",
    "            method=seg_method,\n",
    "            blur_size=blur_size,\n",
    "            adaptive_block_size=adaptive_block_size,\n",
    "            adaptive_c=adaptive_c\n",
    "        )\n",
    "        \n",
    "        # Initialize density classifier\n",
    "        self.density_model = IntensityDensityClassifier(\n",
    "            n_classes=n_density_classes,\n",
    "            method=density_method,\n",
    "            blur_size=blur_size\n",
    "        )\n",
    "        \n",
    "        self.n_density_classes = n_density_classes\n",
    "    \n",
    "    def process(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray, dict]:\n",
    "        \"\"\"\n",
    "        Process image: segment and classify densities in one step\n",
    "        \n",
    "        Args:\n",
    "            image: Input grayscale image (H, W) or (H, W, C)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (signal_mask, density_classification, statistics)\n",
    "            - signal_mask: Binary mask (1 = signal, 0 = background)\n",
    "            - density_classification: Multi-class mask (0 = background, 1..n = density classes)\n",
    "            - statistics: Dictionary with classification statistics\n",
    "        \"\"\"\n",
    "        # Handle multi-channel images\n",
    "        if len(image.shape) == 3:\n",
    "            if image.shape[2] == 1:\n",
    "                image = image[:, :, 0]\n",
    "            else:\n",
    "                image = np.mean(image, axis=2)\n",
    "        \n",
    "        # Step 1: Segment signal from background\n",
    "        signal_mask = self.seg_model.segment(image)\n",
    "        \n",
    "        # Step 2: Classify densities within signal regions\n",
    "        density_classification, stats = self.density_model.classify_with_stats(\n",
    "            image, signal_mask\n",
    "        )\n",
    "        \n",
    "        return signal_mask, density_classification, stats\n",
    "    \n",
    "    def process_image(self, image_path: Union[str, Path],\n",
    "                     output_signal_path: Optional[Union[str, Path]] = None,\n",
    "                     output_density_path: Optional[Union[str, Path]] = None,\n",
    "                     visualize: bool = False) -> Tuple[np.ndarray, np.ndarray, dict]:\n",
    "        \"\"\"\n",
    "        Process image file\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to input image\n",
    "            output_signal_path: Optional path to save signal mask\n",
    "            output_density_path: Optional path to save density classification\n",
    "            visualize: Whether to show visualization\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (signal_mask, density_classification, statistics)\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        if isinstance(image_path, str):\n",
    "            image_path = Path(image_path)\n",
    "        \n",
    "        image = np.array(Image.open(image_path).convert('L'))\n",
    "        \n",
    "        # Process\n",
    "        signal_mask, density_classification, stats = self.process(image)\n",
    "        \n",
    "        # Save if requested\n",
    "        if output_signal_path:\n",
    "            if isinstance(output_signal_path, str):\n",
    "                output_signal_path = Path(output_signal_path)\n",
    "            output_signal_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            Image.fromarray(signal_mask * 255).save(output_signal_path)\n",
    "        \n",
    "        if output_density_path:\n",
    "            if isinstance(output_density_path, str):\n",
    "                output_density_path = Path(output_density_path)\n",
    "            output_density_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            # Scale density classes for visualization (0-255)\n",
    "            density_vis = (density_classification * (255 // self.n_density_classes)).astype(np.uint8)\n",
    "            Image.fromarray(density_vis).save(output_density_path)\n",
    "        \n",
    "        # Visualize if requested\n",
    "        if visualize:\n",
    "            self.visualize(image, signal_mask, density_classification, stats)\n",
    "        \n",
    "        return signal_mask, density_classification, stats\n",
    "    \n",
    "    def process_directory(self, input_dir: Union[str, Path],\n",
    "                         output_dir: Union[str, Path],\n",
    "                         pattern: str = \"*.tif*\"):\n",
    "        \"\"\"\n",
    "        Process all images in a directory\n",
    "        \n",
    "        Args:\n",
    "            input_dir: Directory containing input images\n",
    "            output_dir: Directory to save results\n",
    "            pattern: File pattern to match\n",
    "        \"\"\"\n",
    "        input_dir = Path(input_dir)\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        signal_dir = output_dir / \"signal_masks\"\n",
    "        density_dir = output_dir / \"density_classifications\"\n",
    "        signal_dir.mkdir(exist_ok=True)\n",
    "        density_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        image_files = list(input_dir.glob(pattern))\n",
    "        print(f\"Found {len(image_files)} images\")\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            signal_path = signal_dir / f\"{img_path.stem}_signal{img_path.suffix}\"\n",
    "            density_path = density_dir / f\"{img_path.stem}_density{img_path.suffix}\"\n",
    "            \n",
    "            try:\n",
    "                self.process_image(img_path, signal_path, density_path)\n",
    "                print(f\"Processed: {img_path.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path.name}: {e}\")\n",
    "    \n",
    "    def visualize(self, image: np.ndarray, signal_mask: np.ndarray,\n",
    "                  density_classification: np.ndarray, stats: Optional[dict] = None):\n",
    "        \"\"\"Visualize segmentation and density classification\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0, 0].imshow(image, cmap='gray')\n",
    "        axes[0, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Signal mask\n",
    "        axes[0, 1].imshow(signal_mask, cmap='gray')\n",
    "        axes[0, 1].set_title('Signal Segmentation\\n(White = Signal, Black = Background)', \n",
    "                            fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # Density classification (colored)\n",
    "        cmap = plt.cm.get_cmap('viridis', self.n_density_classes)\n",
    "        colored = cmap(density_classification / max(self.n_density_classes, 1))\n",
    "        colored[density_classification == 0] = [0, 0, 0, 1]  # Black for background\n",
    "        axes[0, 2].imshow(colored)\n",
    "        axes[0, 2].set_title(f'Density Classification\\n({self.n_density_classes} classes)', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[0, 2].axis('off')\n",
    "        \n",
    "        # Overlay: Image + Density Classes\n",
    "        overlay = image.copy().astype(np.float32)\n",
    "        overlay = overlay / overlay.max()\n",
    "        overlay_rgb = np.stack([overlay] * 3, axis=-1)\n",
    "        \n",
    "        for class_id in range(1, self.n_density_classes + 1):\n",
    "            class_mask = density_classification == class_id\n",
    "            color = cmap(class_id / self.n_density_classes)[:3]\n",
    "            overlay_rgb[class_mask] = color\n",
    "        \n",
    "        axes[1, 0].imshow(overlay_rgb)\n",
    "        axes[1, 0].set_title('Overlay: Image + Density Classes', fontsize=12, fontweight='bold')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # Statistics plot\n",
    "        if stats:\n",
    "            axes[1, 1].axis('off')\n",
    "            stats_text = f\"Classification Statistics\\n\\n\"\n",
    "            stats_text += f\"Classes: {stats['n_classes']}\\n\"\n",
    "            if stats['thresholds']:\n",
    "                stats_text += f\"Thresholds: {[f'{t:.1f}' for t in stats['thresholds']]}\\n\\n\"\n",
    "            \n",
    "            for class_id in range(1, self.n_density_classes + 1):\n",
    "                if class_id in stats['class_counts']:\n",
    "                    count = stats['class_counts'][class_id]\n",
    "                    pct = 100 * count / density_classification.size\n",
    "                    stats_text += f\"Class {class_id}: {count} pixels ({pct:.1f}%)\\n\"\n",
    "                    if class_id in stats['class_intensities']:\n",
    "                        int_stats = stats['class_intensities'][class_id]\n",
    "                        stats_text += f\"  Intensity: {int_stats['mean']:.1f} ± {int_stats['std']:.1f}\\n\"\n",
    "            \n",
    "            axes[1, 1].text(0.1, 0.5, stats_text, fontsize=10, \n",
    "                           verticalalignment='center', family='monospace')\n",
    "            axes[1, 1].set_title('Statistics', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Intensity histogram\n",
    "        signal_intensities = image[signal_mask == 1]\n",
    "        if len(signal_intensities) > 0:\n",
    "            axes[1, 2].hist(signal_intensities, bins=50, edgecolor='black', alpha=0.7)\n",
    "            if stats and stats['thresholds']:\n",
    "                for threshold in stats['thresholds']:\n",
    "                    axes[1, 2].axvline(threshold, color='red', linestyle='--', \n",
    "                                      linewidth=2, label=f'Threshold: {threshold:.1f}')\n",
    "            axes[1, 2].set_xlabel('Intensity', fontsize=10)\n",
    "            axes[1, 2].set_ylabel('Frequency', fontsize=10)\n",
    "            axes[1, 2].set_title('Signal Intensity Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[1, 2].legend(fontsize=8)\n",
    "            axes[1, 2].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class UnifiedSegmentationDensityUNet:\n",
    "    \"\"\"\n",
    "    Unified deep learning model that performs both segmentation and density classification.\n",
    "    Uses a single U-Net architecture with multi-class output.\n",
    "    \n",
    "    Requires TensorFlow and training data.\n",
    "    \n",
    "    Example:\n",
    "        model = UnifiedSegmentationDensityUNet(n_density_classes=3)\n",
    "        model.build_model()\n",
    "        # Train model...\n",
    "        signal_mask, density_class = model.process(image)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(512, 512, 1), n_density_classes=3, learning_rate=1e-4):\n",
    "        \"\"\"\n",
    "        Initialize unified U-Net model\n",
    "        \n",
    "        Args:\n",
    "            input_shape: Input image shape (height, width, channels)\n",
    "            n_density_classes: Number of density classes (excluding background)\n",
    "            learning_rate: Learning rate for optimizer\n",
    "        \"\"\"\n",
    "        if not HAS_TF:\n",
    "            raise ImportError(\"TensorFlow required for U-Net model. Install with: pip install tensorflow\")\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.n_density_classes = n_density_classes\n",
    "        self.n_classes = n_density_classes + 1  # +1 for background\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = None\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Build unified U-Net architecture for segmentation + density classification\"\"\"\n",
    "        inputs = Input(self.input_shape)\n",
    "        \n",
    "        # Encoder\n",
    "        # Block 1\n",
    "        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "        bn1 = BatchNormalization()(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n",
    "        \n",
    "        # Block 2\n",
    "        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "        bn2 = BatchNormalization()(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n",
    "        \n",
    "        # Block 3\n",
    "        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "        bn3 = BatchNormalization()(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n",
    "        \n",
    "        # Block 4\n",
    "        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "        bn4 = BatchNormalization()(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n",
    "        \n",
    "        # Bottleneck\n",
    "        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "        bn5 = BatchNormalization()(conv5)\n",
    "        \n",
    "        # Decoder\n",
    "        # Block 6\n",
    "        up6 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same', kernel_initializer='he_normal')(bn5)\n",
    "        merge6 = Concatenate(axis=3)([bn4, up6])\n",
    "        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "        bn6 = BatchNormalization()(conv6)\n",
    "        \n",
    "        # Block 7\n",
    "        up7 = Conv2DTranspose(256, 2, strides=(2, 2), padding='same', kernel_initializer='he_normal')(bn6)\n",
    "        merge7 = Concatenate(axis=3)([bn3, up7])\n",
    "        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "        bn7 = BatchNormalization()(conv7)\n",
    "        \n",
    "        # Block 8\n",
    "        up8 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same', kernel_initializer='he_normal')(bn7)\n",
    "        merge8 = Concatenate(axis=3)([bn2, up8])\n",
    "        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "        bn8 = BatchNormalization()(conv8)\n",
    "        \n",
    "        # Block 9\n",
    "        up9 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same', kernel_initializer='he_normal')(bn8)\n",
    "        merge9 = Concatenate(axis=3)([bn1, up9])\n",
    "        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "        bn9 = BatchNormalization()(conv9)\n",
    "        \n",
    "        # Output: softmax for multi-class (background + density classes)\n",
    "        outputs = Conv2D(self.n_classes, 1, activation='softmax')(bn9)\n",
    "        \n",
    "        model = Model(inputs=inputs, outputs=outputs, name='UnifiedSegmentationDensityUNet')\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=self.learning_rate),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def preprocess_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Preprocess image for model input\"\"\"\n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            if image.shape[2] == 1:\n",
    "                image = image[:, :, 0]\n",
    "            else:\n",
    "                image = np.mean(image, axis=2)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        if image.max() > 1.0:\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "        \n",
    "        # Resize if needed\n",
    "        if image.shape[:2] != self.input_shape[:2]:\n",
    "            from PIL import Image as PILImage\n",
    "            img_pil = PILImage.fromarray((image * 255).astype(np.uint8))\n",
    "            img_pil = img_pil.resize((self.input_shape[1], self.input_shape[0]))\n",
    "            image = np.array(img_pil).astype(np.float32) / 255.0\n",
    "        \n",
    "        # Add batch and channel dimensions\n",
    "        image = np.expand_dims(image, axis=0)  # (1, H, W)\n",
    "        image = np.expand_dims(image, axis=-1)  # (1, H, W, 1)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def process(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Process image: segment and classify densities in one forward pass\n",
    "        \n",
    "        Args:\n",
    "            image: Input image (H, W) or (H, W, C)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (signal_mask, density_classification)\n",
    "            - signal_mask: Binary mask (1 = signal, 0 = background)\n",
    "            - density_classification: Multi-class mask (0 = background, 1..n = density classes)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not built. Call build_model() first.\")\n",
    "        \n",
    "        # Preprocess\n",
    "        preprocessed = self.preprocess_image(image)\n",
    "        \n",
    "        # Predict\n",
    "        pred = self.model.predict(preprocessed, verbose=0)\n",
    "        \n",
    "        # Get class predictions (argmax)\n",
    "        classification = np.argmax(pred[0], axis=-1).astype(np.uint8)\n",
    "        \n",
    "        # Separate into signal mask and density classification\n",
    "        signal_mask = (classification > 0).astype(np.uint8)  # Any non-zero = signal\n",
    "        \n",
    "        # Density classification: 0 = background, 1..n = density classes\n",
    "        density_classification = classification.copy()\n",
    "        \n",
    "        return signal_mask, density_classification\n",
    "    \n",
    "    def load_model(self, model_path: str):\n",
    "        \"\"\"Load trained model from file\"\"\"\n",
    "        if not HAS_TF:\n",
    "            raise ImportError(\"TensorFlow required to load model\")\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.input_shape = self.model.input_shape[1:]  # Remove batch dimension\n",
    "        # Infer n_classes from output shape\n",
    "        self.n_classes = self.model.output_shape[-1]\n",
    "        self.n_density_classes = self.n_classes - 1\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"UNIFIED SEGMENTATION & DENSITY CLASSIFICATION MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example: Create test image\n",
    "    test_image = np.ones((512, 512), dtype=np.uint8) * 200  # Bright background\n",
    "    test_image[200:300, 200:300] = 30   # Very dark (low density)\n",
    "    test_image[100:150, 400:450] = 50   # Medium dark (medium density)\n",
    "    test_image[350:400, 100:200] = 70   # Less dark (high density)\n",
    "    \n",
    "    # Initialize unified model\n",
    "    print(\"\\nInitializing unified model...\")\n",
    "    model = UnifiedSegmentationDensityModel(\n",
    "        seg_method='otsu',\n",
    "        density_method='percentile',\n",
    "        n_density_classes=3,\n",
    "        blur_size=5\n",
    "    )\n",
    "    \n",
    "    # Process image\n",
    "    print(\"Processing image...\")\n",
    "    signal_mask, density_class, stats = model.process(test_image)\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Signal mask shape: {signal_mask.shape}\")\n",
    "    print(f\"  Density classification shape: {density_class.shape}\")\n",
    "    print(f\"  Signal pixels: {np.sum(signal_mask == 1)}\")\n",
    "    print(f\"  Density classes found: {np.unique(density_class)}\")\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  Thresholds: {stats['thresholds']}\")\n",
    "    for class_id, count in stats['class_counts'].items():\n",
    "        print(f\"  Class {class_id}: {count} pixels\")\n",
    "        if class_id in stats['class_intensities']:\n",
    "            int_stats = stats['class_intensities'][class_id]\n",
    "            print(f\"    Mean intensity: {int_stats['mean']:.1f} ± {int_stats['std']:.1f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Usage Examples:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"  # Process numpy array\")\n",
    "    print(\"  model = UnifiedSegmentationDensityModel(n_density_classes=3)\")\n",
    "    print(\"  signal_mask, density_class, stats = model.process(image)\")\n",
    "    print(\"\\n  # Process image file\")\n",
    "    print(\"  model.process_image('input.tif', 'signal.tif', 'density.tif', visualize=True)\")\n",
    "    print(\"\\n  # Process directory\")\n",
    "    print(\"  model.process_directory('input_dir/', 'output_dir/')\")\n",
    "    \n",
    "    if HAS_TF:\n",
    "        print(\"\\n  # Deep learning model (requires training)\")\n",
    "        print(\"  unet_model = UnifiedSegmentationDensityUNet(n_density_classes=3)\")\n",
    "        print(\"  unet_model.build_model()\")\n",
    "        print(\"  # Train model...\")\n",
    "        print(\"  signal_mask, density_class = unet_model.process(image)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e0fee-1c26-47ef-9a2d-455831b4aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, train_images, train_masks, val_images=None, val_masks=None,\n",
    "              batch_size=8, epochs=50, model_save_path=None):\n",
    "        \"\"\"\n",
    "        Train the U-Net on multiple images.\n",
    "\n",
    "        Args:\n",
    "            train_images: np.ndarray of shape (N, H, W) or (N, H, W, C)\n",
    "            train_masks: np.ndarray of shape (N, H, W) with integer labels (0=background, 1..n)\n",
    "            val_images: optional validation images\n",
    "            val_masks: optional validation masks\n",
    "            batch_size: batch size for training\n",
    "            epochs: number of epochs\n",
    "            model_save_path: path to save best model\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not built. Call build_model() first.\")\n",
    "        \n",
    "        # Ensure 4D input: (N, H, W, 1)\n",
    "        def preprocess_dataset(images):\n",
    "            if len(images.shape) == 3:  # (N, H, W)\n",
    "                images = images[..., np.newaxis]\n",
    "            images = images.astype('float32') / 255.0\n",
    "            return images\n",
    "        \n",
    "        X_train = preprocess_dataset(train_images)\n",
    "        y_train = train_masks.astype('int32')\n",
    "        \n",
    "        if val_images is not None and val_masks is not None:\n",
    "            X_val = preprocess_dataset(val_images)\n",
    "            y_val = val_masks.astype('int32')\n",
    "            validation_data = (X_val, y_val)\n",
    "        else:\n",
    "            validation_data = None\n",
    "        \n",
    "        callbacks = []\n",
    "        if model_save_path:\n",
    "            checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss',\n",
    "                                         save_best_only=True, verbose=1)\n",
    "            callbacks.append(checkpoint)\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "        callbacks.append(early_stop)\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=validation_data,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8e7fc6-4eeb-4655-9ddf-860fee9360fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UNIFIED SEGMENTATION & DENSITY CLASSIFICATION MODEL\n",
      "============================================================\n",
      "\n",
      "Initializing unified model...\n",
      "\n",
      "Example 1: Processing numpy array...\n",
      "\n",
      "Results:\n",
      "  Signal mask shape: (512, 512)\n",
      "  Density classification shape: (512, 512)\n",
      "  Signal pixels: 17492\n",
      "  Density classes found: [0 1 2 3]\n",
      "\n",
      "Statistics:\n",
      "  Thresholds: [30.0, 50.0]\n",
      "  Class 1: 9216 pixels\n",
      "    Mean intensity: 30.0 ± 0.0\n",
      "  Class 2: 2500 pixels\n",
      "    Mean intensity: 46.9 ± 7.2\n",
      "  Class 3: 5776 pixels\n",
      "    Mean intensity: 65.9 ± 11.0\n",
      "\n",
      "============================================================\n",
      "Example 2: Processing Directory of Images\n",
      "============================================================\n",
      "\n",
      "To process a directory of images, use:\n",
      "  model.process_directory('path/to/input/images/', 'path/to/output/')\n",
      "\n",
      "Example:\n",
      "  model.process_directory('../testraw/', '../results/unified/')\n",
      "\n",
      "This will:\n",
      "  - Find all .tif/.tiff files in the input directory\n",
      "  - Process each image\n",
      "  - Save signal masks to: output_dir/signal_masks/\n",
      "  - Save density classifications to: output_dir/density_classifications/\n",
      "\n",
      "============================================================\n",
      "Usage Examples:\n",
      "============================================================\n",
      "\n",
      "1. Process numpy array:\n",
      "   model = UnifiedSegmentationDensityModel(n_density_classes=3)\n",
      "   signal_mask, density_class, stats = model.process(image)\n",
      "\n",
      "2. Process single image file:\n",
      "   model.process_image('input.tif', 'signal.tif', 'density.tif', visualize=True)\n",
      "\n",
      "3. Process directory of images:\n",
      "   # Process all .tif files in a directory\n",
      "   model.process_directory('../testraw/', '../results/unified/')\n",
      "   \n",
      "   # Process only .png files\n",
      "   model.process_directory('input/', 'output/', pattern='*.png')\n",
      "   \n",
      "   # Process with custom pattern\n",
      "   model.process_directory('images/', 'results/', pattern='*.tiff')\n",
      "\n",
      "   Output structure:\n",
      "   results/\n",
      "   ├── signal_masks/          # Binary masks (1=signal, 0=background)\n",
      "   │   ├── image1_signal.tif\n",
      "   │   └── image2_signal.tif\n",
      "   └── density_classifications/  # Multi-class masks (0=bg, 1-3=density)\n",
      "       ├── image1_density.tif\n",
      "       └── image2_density.tif\n",
      "\n",
      "  # Deep learning model (requires training)\n",
      "  unet_model = UnifiedSegmentationDensityUNet(n_density_classes=3)\n",
      "  unet_model.build_model()\n",
      "  # Train model...\n",
      "  signal_mask, density_class = unet_model.process(image)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unified Segmentation and Density Classification Model - Standalone Version\n",
    "\n",
    "This file contains the unified models with all dependencies included.\n",
    "Performs both signal-background segmentation and intensity density classification in one step.\n",
    "\n",
    "Usage:\n",
    "    from unified_model_standalone import UnifiedSegmentationDensityModel\n",
    "    \n",
    "    model = UnifiedSegmentationDensityModel(n_density_classes=3)\n",
    "    signal_mask, density_class, stats = model.process(image)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import Tuple, Optional, Union, Dict\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning imports (optional, for U-Net model)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.layers import (\n",
    "        Input, Conv2D, MaxPooling2D, UpSampling2D,\n",
    "        Concatenate, Conv2DTranspose, BatchNormalization\n",
    "    )\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    HAS_TF = True\n",
    "except ImportError:\n",
    "    HAS_TF = False\n",
    "    ModelCheckpoint = None\n",
    "    EarlyStopping = None\n",
    "    print(\"Warning: TensorFlow not available. U-Net model will not work.\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DEPENDENCY CLASSES\n",
    "# ============================================================================\n",
    "\n",
    "class InverseThresholdModel:\n",
    "    \"\"\"\n",
    "    Simple thresholding-based model for separating dark signal from bright background.\n",
    "    Used internally by the unified model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, method='otsu', blur_size=5, adaptive_block_size=11, adaptive_c=2):\n",
    "        \"\"\"\n",
    "        Initialize thresholding model\n",
    "        \n",
    "        Args:\n",
    "            method: 'otsu', 'adaptive', or 'percentile'\n",
    "            blur_size: Gaussian blur kernel size (odd number, 0 to disable)\n",
    "            adaptive_block_size: Block size for adaptive thresholding (odd number)\n",
    "            adaptive_c: Constant subtracted from mean in adaptive thresholding\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.blur_size = blur_size\n",
    "        self.adaptive_block_size = adaptive_block_size\n",
    "        self.adaptive_c = adaptive_c\n",
    "    \n",
    "    def preprocess(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Preprocess image: ensure uint8, apply blur if needed\"\"\"\n",
    "        # Convert to uint8 if needed\n",
    "        if image.dtype != np.uint8:\n",
    "            if image.max() <= 1.0:\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "            else:\n",
    "                image = image.astype(np.uint8)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        if self.blur_size > 0:\n",
    "            image = cv2.GaussianBlur(image, (self.blur_size, self.blur_size), 0)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def segment(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Segment image: dark regions (signal) vs bright regions (background)\n",
    "        \n",
    "        Args:\n",
    "            image: Input grayscale image (H, W) or (H, W, C)\n",
    "            \n",
    "        Returns:\n",
    "            Binary mask: 1 = signal (dark), 0 = background (bright)\n",
    "        \"\"\"\n",
    "        # Handle multi-channel images\n",
    "        if len(image.shape) == 3:\n",
    "            if image.shape[2] == 1:\n",
    "                image = image[:, :, 0]\n",
    "            else:\n",
    "                image = np.mean(image, axis=2)\n",
    "        \n",
    "        # Preprocess\n",
    "        image = self.preprocess(image)\n",
    "        \n",
    "        # Apply thresholding method\n",
    "        if self.method == 'otsu':\n",
    "            # Otsu's method: automatically finds optimal threshold\n",
    "            threshold_value, binary = cv2.threshold(\n",
    "                image, 0, 1, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "            )\n",
    "            # THRESH_BINARY_INV: dark pixels (low intensity) become 1\n",
    "            \n",
    "        elif self.method == 'adaptive':\n",
    "            # Adaptive thresholding: handles varying illumination\n",
    "            binary = cv2.adaptiveThreshold(\n",
    "                image, 1, \n",
    "                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                cv2.THRESH_BINARY_INV,\n",
    "                self.adaptive_block_size,\n",
    "                self.adaptive_c\n",
    "            )\n",
    "            \n",
    "        elif self.method == 'percentile':\n",
    "            # Percentile-based thresholding\n",
    "            threshold_value = np.percentile(image, 30)  # Bottom 30% = signal\n",
    "            binary = (image < threshold_value).astype(np.uint8)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {self.method}\")\n",
    "        \n",
    "        return binary.astype(np.uint8)\n",
    "\n",
    "\n",
    "class IntensityDensityClassifier:\n",
    "    \"\"\"\n",
    "    Classifies different intensity densities within low-intensity signal regions.\n",
    "    Used internally by the unified model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_classes=3, method='percentile', blur_size=3):\n",
    "        \"\"\"\n",
    "        Initialize density classifier\n",
    "        \n",
    "        Args:\n",
    "            n_classes: Number of density classes (e.g., 3 = low/medium/high density)\n",
    "            method: 'percentile', 'kmeans', or 'equal_width'\n",
    "            blur_size: Gaussian blur kernel size for smoothing (odd number, 0 to disable)\n",
    "        \"\"\"\n",
    "        self.n_classes = n_classes\n",
    "        self.method = method\n",
    "        self.blur_size = blur_size\n",
    "        self.thresholds = None\n",
    "    \n",
    "    def preprocess(self, image: np.ndarray, signal_mask: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Preprocess image and mask: extract signal regions only\"\"\"\n",
    "        # Ensure uint8\n",
    "        if image.dtype != np.uint8:\n",
    "            if image.max() <= 1.0:\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "            else:\n",
    "                image = image.astype(np.uint8)\n",
    "        \n",
    "        # Ensure binary mask\n",
    "        if signal_mask.dtype != np.uint8:\n",
    "            signal_mask = (signal_mask > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # Apply blur to reduce noise\n",
    "        if self.blur_size > 0:\n",
    "            image = cv2.GaussianBlur(image, (self.blur_size, self.blur_size), 0)\n",
    "        \n",
    "        return image, signal_mask\n",
    "    \n",
    "    def compute_thresholds(self, image: np.ndarray, signal_mask: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute intensity thresholds for density classification\"\"\"\n",
    "        # Extract signal region intensities\n",
    "        signal_intensities = image[signal_mask == 1]\n",
    "        \n",
    "        if len(signal_intensities) == 0:\n",
    "            # No signal regions, return default thresholds\n",
    "            return np.linspace(0, 255, self.n_classes + 1)[1:-1]\n",
    "        \n",
    "        if self.method == 'percentile':\n",
    "            # Use percentiles to divide into equal-sized groups\n",
    "            percentiles = np.linspace(0, 100, self.n_classes + 1)[1:-1]\n",
    "            thresholds = np.percentile(signal_intensities, percentiles)\n",
    "            \n",
    "        elif self.method == 'equal_width':\n",
    "            # Divide intensity range into equal-width bins\n",
    "            min_intensity = signal_intensities.min()\n",
    "            max_intensity = signal_intensities.max()\n",
    "            thresholds = np.linspace(min_intensity, max_intensity, self.n_classes + 1)[1:-1]\n",
    "            \n",
    "        elif self.method == 'kmeans':\n",
    "            # Use k-means clustering (simple implementation)\n",
    "            try:\n",
    "                from sklearn.cluster import KMeans\n",
    "                intensities_reshaped = signal_intensities.reshape(-1, 1)\n",
    "                kmeans = KMeans(n_clusters=self.n_classes, random_state=42, n_init=10)\n",
    "                kmeans.fit(intensities_reshaped)\n",
    "                centers = np.sort(kmeans.cluster_centers_.flatten())\n",
    "                thresholds = (centers[:-1] + centers[1:]) / 2\n",
    "            except ImportError:\n",
    "                raise ImportError(\"scikit-learn required for kmeans method. Install with: pip install scikit-learn\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {self.method}\")\n",
    "        \n",
    "        return thresholds\n",
    "    \n",
    "    def classify(self, image: np.ndarray, signal_mask: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Classify signal regions into different density classes\n",
    "        \n",
    "        Args:\n",
    "            image: Original grayscale image (H, W) or (H, W, C)\n",
    "            signal_mask: Binary mask where 1 = signal regions (H, W)\n",
    "            \n",
    "        Returns:\n",
    "            Multi-class mask: 0 = background, 1..n_classes = density classes\n",
    "            (1 = lowest density, n_classes = highest density)\n",
    "        \"\"\"\n",
    "        # Handle multi-channel images\n",
    "        if len(image.shape) == 3:\n",
    "            if image.shape[2] == 1:\n",
    "                image = image[:, :, 0]\n",
    "            else:\n",
    "                image = np.mean(image, axis=2)\n",
    "        \n",
    "        # Preprocess\n",
    "        image, signal_mask = self.preprocess(image, signal_mask)\n",
    "        \n",
    "        # Compute thresholds\n",
    "        thresholds = self.compute_thresholds(image, signal_mask)\n",
    "        self.thresholds = thresholds\n",
    "        \n",
    "        # Initialize classification mask (0 = background)\n",
    "        classification = np.zeros_like(image, dtype=np.uint8)\n",
    "        \n",
    "        # Classify signal regions\n",
    "        signal_pixels = signal_mask == 1\n",
    "        \n",
    "        # Assign classes based on thresholds\n",
    "        # Class 1: lowest density (darkest)\n",
    "        classification[signal_pixels & (image <= thresholds[0])] = 1\n",
    "        \n",
    "        # Middle classes\n",
    "        for i in range(1, len(thresholds)):\n",
    "            classification[signal_pixels & (image > thresholds[i-1]) & (image <= thresholds[i])] = i + 1\n",
    "        \n",
    "        # Class n_classes: highest density (brightest signal)\n",
    "        classification[signal_pixels & (image > thresholds[-1])] = self.n_classes\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    def classify_with_stats(self, image: np.ndarray, signal_mask: np.ndarray) -> Tuple[np.ndarray, dict]:\n",
    "        \"\"\"\n",
    "        Classify and return statistics\n",
    "        \n",
    "        Args:\n",
    "            image: Original grayscale image\n",
    "            signal_mask: Binary mask where 1 = signal regions\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (classification_mask, statistics_dict)\n",
    "        \"\"\"\n",
    "        classification = self.classify(image, signal_mask)\n",
    "        \n",
    "        # Compute statistics for each class\n",
    "        stats = {\n",
    "            'n_classes': self.n_classes,\n",
    "            'thresholds': self.thresholds.tolist() if self.thresholds is not None else None,\n",
    "            'class_counts': {},\n",
    "            'class_intensities': {}\n",
    "        }\n",
    "        \n",
    "        for class_id in range(1, self.n_classes + 1):\n",
    "            class_mask = classification == class_id\n",
    "            stats['class_counts'][class_id] = int(np.sum(class_mask))\n",
    "            \n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_intensities = image[class_mask]\n",
    "                stats['class_intensities'][class_id] = {\n",
    "                    'mean': float(np.mean(class_intensities)),\n",
    "                    'std': float(np.std(class_intensities)),\n",
    "                    'min': int(np.min(class_intensities)),\n",
    "                    'max': int(np.max(class_intensities))\n",
    "                }\n",
    "        \n",
    "        return classification, stats\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UNIFIED MODELS\n",
    "# ============================================================================\n",
    "\n",
    "class UnifiedSegmentationDensityModel:\n",
    "    \"\"\"\n",
    "    Unified model that performs both segmentation and density classification in one step.\n",
    "    Combines signal-background separation with intensity density classification.\n",
    "    \n",
    "    This is a thresholding-based model that requires no training.\n",
    "    \n",
    "    Example:\n",
    "        model = UnifiedSegmentationDensityModel(n_density_classes=3)\n",
    "        signal_mask, density_class, stats = model.process(image)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 seg_method='otsu',\n",
    "                 density_method='percentile',\n",
    "                 n_density_classes=3,\n",
    "                 blur_size=5,\n",
    "                 adaptive_block_size=11,\n",
    "                 adaptive_c=2):\n",
    "        \"\"\"\n",
    "        Initialize unified model\n",
    "        \n",
    "        Args:\n",
    "            seg_method: Segmentation method ('otsu', 'adaptive', 'percentile')\n",
    "            density_method: Density classification method ('percentile', 'equal_width', 'kmeans')\n",
    "            n_density_classes: Number of density classes (default 3)\n",
    "            blur_size: Gaussian blur kernel size\n",
    "            adaptive_block_size: Block size for adaptive thresholding\n",
    "            adaptive_c: Constant for adaptive thresholding\n",
    "        \"\"\"\n",
    "        # Initialize segmentation model\n",
    "        self.seg_model = InverseThresholdModel(\n",
    "            method=seg_method,\n",
    "            blur_size=blur_size,\n",
    "            adaptive_block_size=adaptive_block_size,\n",
    "            adaptive_c=adaptive_c\n",
    "        )\n",
    "        \n",
    "        # Initialize density classifier\n",
    "        self.density_model = IntensityDensityClassifier(\n",
    "            n_classes=n_density_classes,\n",
    "            method=density_method,\n",
    "            blur_size=blur_size\n",
    "        )\n",
    "        \n",
    "        self.n_density_classes = n_density_classes\n",
    "    \n",
    "    def process(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray, dict]:\n",
    "        \"\"\"\n",
    "        Process image: segment and classify densities in one step\n",
    "        \n",
    "        Args:\n",
    "            image: Input grayscale image (H, W) or (H, W, C)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (signal_mask, density_classification, statistics)\n",
    "            - signal_mask: Binary mask (1 = signal, 0 = background)\n",
    "            - density_classification: Multi-class mask (0 = background, 1..n = density classes)\n",
    "            - statistics: Dictionary with classification statistics\n",
    "        \"\"\"\n",
    "        # Handle multi-channel images\n",
    "        if len(image.shape) == 3:\n",
    "            if image.shape[2] == 1:\n",
    "                image = image[:, :, 0]\n",
    "            else:\n",
    "                image = np.mean(image, axis=2)\n",
    "        \n",
    "        # Step 1: Segment signal from background\n",
    "        signal_mask = self.seg_model.segment(image)\n",
    "        \n",
    "        # Step 2: Classify densities within signal regions\n",
    "        density_classification, stats = self.density_model.classify_with_stats(\n",
    "            image, signal_mask\n",
    "        )\n",
    "        \n",
    "        return signal_mask, density_classification, stats\n",
    "    \n",
    "    def process_image(self, image_path: Union[str, Path],\n",
    "                     output_signal_path: Optional[Union[str, Path]] = None,\n",
    "                     output_density_path: Optional[Union[str, Path]] = None,\n",
    "                     visualize: bool = False) -> Tuple[np.ndarray, np.ndarray, dict]:\n",
    "        \"\"\"\n",
    "        Process image file\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to input image\n",
    "            output_signal_path: Optional path to save signal mask\n",
    "            output_density_path: Optional path to save density classification\n",
    "            visualize: Whether to show visualization\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (signal_mask, density_classification, statistics)\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        if isinstance(image_path, str):\n",
    "            image_path = Path(image_path)\n",
    "        \n",
    "        image = np.array(Image.open(image_path).convert('L'))\n",
    "        \n",
    "        # Process\n",
    "        signal_mask, density_classification, stats = self.process(image)\n",
    "        \n",
    "        # Save if requested\n",
    "        if output_signal_path:\n",
    "            if isinstance(output_signal_path, str):\n",
    "                output_signal_path = Path(output_signal_path)\n",
    "            output_signal_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            Image.fromarray(signal_mask * 255).save(output_signal_path)\n",
    "        \n",
    "        if output_density_path:\n",
    "            if isinstance(output_density_path, str):\n",
    "                output_density_path = Path(output_density_path)\n",
    "            output_density_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            # Scale density classes for visualization (0-255)\n",
    "            density_vis = (density_classification * (255 // self.n_density_classes)).astype(np.uint8)\n",
    "            Image.fromarray(density_vis).save(output_density_path)\n",
    "        \n",
    "        # Visualize if requested\n",
    "        if visualize:\n",
    "            self.visualize(image, signal_mask, density_classification, stats)\n",
    "        \n",
    "        return signal_mask, density_classification, stats\n",
    "    \n",
    "    def process_directory(self, input_dir: Union[str, Path],\n",
    "                         output_dir: Union[str, Path],\n",
    "                         pattern: str = \"*.tif*\"):\n",
    "        \"\"\"\n",
    "        Process all images in a directory\n",
    "        \n",
    "        Args:\n",
    "            input_dir: Directory containing input images (e.g., '../testraw/' or 'C:/path/to/images/')\n",
    "            output_dir: Directory to save results (e.g., '../results/unified/' or 'C:/path/to/output/')\n",
    "            pattern: File pattern to match (default: \"*.tif*\" for .tif, .tiff files)\n",
    "                    Examples: \"*.tif*\", \"*.png\", \"*.jpg\", \"*.tif\"\n",
    "        \n",
    "        Returns:\n",
    "            dict: Summary statistics with counts of processed images\n",
    "        \n",
    "        Example:\n",
    "            # Process all .tif files in a directory\n",
    "            model.process_directory('../testraw/', '../results/unified/')\n",
    "            \n",
    "            # Process only .png files\n",
    "            model.process_directory('input/', 'output/', pattern='*.png')\n",
    "            \n",
    "            # Process all image types\n",
    "            model.process_directory('input/', 'output/', pattern='*.{tif,tiff,png,jpg}')\n",
    "        \"\"\"\n",
    "        # Convert to Path objects\n",
    "        input_dir = Path(input_dir)\n",
    "        output_dir = Path(output_dir)\n",
    "        \n",
    "        # Validate input directory\n",
    "        if not input_dir.exists():\n",
    "            raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
    "        if not input_dir.is_dir():\n",
    "            raise ValueError(f\"Input path is not a directory: {input_dir}\")\n",
    "        \n",
    "        # Create output directories\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        signal_dir = output_dir / \"signal_masks\"\n",
    "        density_dir = output_dir / \"density_classifications\"\n",
    "        signal_dir.mkdir(exist_ok=True)\n",
    "        density_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Find all matching image files\n",
    "        image_files = list(input_dir.glob(pattern))\n",
    "        \n",
    "        if len(image_files) == 0:\n",
    "            print(f\"Warning: No images found matching pattern '{pattern}' in {input_dir}\")\n",
    "            return {'processed': 0, 'errors': 0, 'total': 0}\n",
    "        \n",
    "        print(f\"Found {len(image_files)} images in {input_dir}\")\n",
    "        print(f\"Output will be saved to:\")\n",
    "        print(f\"  Signal masks: {signal_dir}\")\n",
    "        print(f\"  Density classifications: {density_dir}\")\n",
    "        print(\"\\nProcessing images...\")\n",
    "        \n",
    "        processed_count = 0\n",
    "        error_count = 0\n",
    "        \n",
    "        for i, img_path in enumerate(image_files, 1):\n",
    "            signal_path = signal_dir / f\"{img_path.stem}_signal{img_path.suffix}\"\n",
    "            density_path = density_dir / f\"{img_path.stem}_density{img_path.suffix}\"\n",
    "            \n",
    "            try:\n",
    "                self.process_image(img_path, signal_path, density_path)\n",
    "                processed_count += 1\n",
    "                print(f\"  [{i}/{len(image_files)}] ✓ Processed: {img_path.name}\")\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"  [{i}/{len(image_files)}] ✗ Error processing {img_path.name}: {e}\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing complete!\")\n",
    "        print(f\"  Total images: {len(image_files)}\")\n",
    "        print(f\"  Successfully processed: {processed_count}\")\n",
    "        print(f\"  Errors: {error_count}\")\n",
    "        print(f\"  Signal masks saved to: {signal_dir}\")\n",
    "        print(f\"  Density classifications saved to: {density_dir}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        return {\n",
    "            'processed': processed_count,\n",
    "            'errors': error_count,\n",
    "            'total': len(image_files),\n",
    "            'signal_dir': str(signal_dir),\n",
    "            'density_dir': str(density_dir)\n",
    "        }\n",
    "    \n",
    "    def visualize(self, image: np.ndarray, signal_mask: np.ndarray,\n",
    "                  density_classification: np.ndarray, stats: Optional[dict] = None):\n",
    "        \"\"\"Visualize segmentation and density classification\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0, 0].imshow(image, cmap='gray')\n",
    "        axes[0, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Signal mask\n",
    "        axes[0, 1].imshow(signal_mask, cmap='gray')\n",
    "        axes[0, 1].set_title('Signal Segmentation\\n(White = Signal, Black = Background)', \n",
    "                            fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # Density classification (colored)\n",
    "        cmap = plt.cm.get_cmap('viridis', self.n_density_classes)\n",
    "        colored = cmap(density_classification / max(self.n_density_classes, 1))\n",
    "        colored[density_classification == 0] = [0, 0, 0, 1]  # Black for background\n",
    "        axes[0, 2].imshow(colored)\n",
    "        axes[0, 2].set_title(f'Density Classification\\n({self.n_density_classes} classes)', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[0, 2].axis('off')\n",
    "        \n",
    "        # Overlay: Image + Density Classes\n",
    "        overlay = image.copy().astype(np.float32)\n",
    "        overlay = overlay / overlay.max()\n",
    "        overlay_rgb = np.stack([overlay] * 3, axis=-1)\n",
    "        \n",
    "        for class_id in range(1, self.n_density_classes + 1):\n",
    "            class_mask = density_classification == class_id\n",
    "            color = cmap(class_id / self.n_density_classes)[:3]\n",
    "            overlay_rgb[class_mask] = color\n",
    "        \n",
    "        axes[1, 0].imshow(overlay_rgb)\n",
    "        axes[1, 0].set_title('Overlay: Image + Density Classes', fontsize=12, fontweight='bold')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # Statistics plot\n",
    "        if stats:\n",
    "            axes[1, 1].axis('off')\n",
    "            stats_text = f\"Classification Statistics\\n\\n\"\n",
    "            stats_text += f\"Classes: {stats['n_classes']}\\n\"\n",
    "            if stats['thresholds']:\n",
    "                stats_text += f\"Thresholds: {[f'{t:.1f}' for t in stats['thresholds']]}\\n\\n\"\n",
    "            \n",
    "            for class_id in range(1, self.n_density_classes + 1):\n",
    "                if class_id in stats['class_counts']:\n",
    "                    count = stats['class_counts'][class_id]\n",
    "                    pct = 100 * count / density_classification.size\n",
    "                    stats_text += f\"Class {class_id}: {count} pixels ({pct:.1f}%)\\n\"\n",
    "                    if class_id in stats['class_intensities']:\n",
    "                        int_stats = stats['class_intensities'][class_id]\n",
    "                        stats_text += f\"  Intensity: {int_stats['mean']:.1f} ± {int_stats['std']:.1f}\\n\"\n",
    "            \n",
    "            axes[1, 1].text(0.1, 0.5, stats_text, fontsize=10, \n",
    "                           verticalalignment='center', family='monospace')\n",
    "            axes[1, 1].set_title('Statistics', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Intensity histogram\n",
    "        signal_intensities = image[signal_mask == 1]\n",
    "        if len(signal_intensities) > 0:\n",
    "            axes[1, 2].hist(signal_intensities, bins=50, edgecolor='black', alpha=0.7)\n",
    "            if stats and stats['thresholds']:\n",
    "                for threshold in stats['thresholds']:\n",
    "                    axes[1, 2].axvline(threshold, color='red', linestyle='--', \n",
    "                                      linewidth=2, label=f'Threshold: {threshold:.1f}')\n",
    "            axes[1, 2].set_xlabel('Intensity', fontsize=10)\n",
    "            axes[1, 2].set_ylabel('Frequency', fontsize=10)\n",
    "            axes[1, 2].set_title('Signal Intensity Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[1, 2].legend(fontsize=8)\n",
    "            axes[1, 2].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class UnifiedSegmentationDensityUNet:\n",
    "    \"\"\"\n",
    "    Unified deep learning model that performs both segmentation and density classification.\n",
    "    Uses a single U-Net architecture with multi-class output.\n",
    "    \n",
    "    Requires TensorFlow and training data.\n",
    "    \n",
    "    Example:\n",
    "        model = UnifiedSegmentationDensityUNet(n_density_classes=3)\n",
    "        model.build_model()\n",
    "        # Train model...\n",
    "        signal_mask, density_class = model.process(image)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(512, 512, 1), n_density_classes=3, learning_rate=1e-4):\n",
    "        \"\"\"\n",
    "        Initialize unified U-Net model\n",
    "        \n",
    "        Args:\n",
    "            input_shape: Input image shape (height, width, channels)\n",
    "            n_density_classes: Number of density classes (excluding background)\n",
    "            learning_rate: Learning rate for optimizer\n",
    "        \"\"\"\n",
    "        if not HAS_TF:\n",
    "            raise ImportError(\"TensorFlow required for U-Net model. Install with: pip install tensorflow\")\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.n_density_classes = n_density_classes\n",
    "        self.n_classes = n_density_classes + 1  # +1 for background\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = None\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Build unified U-Net architecture for segmentation + density classification\"\"\"\n",
    "        inputs = Input(self.input_shape)\n",
    "        \n",
    "        # Encoder\n",
    "        # Block 1\n",
    "        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "        bn1 = BatchNormalization()(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n",
    "        \n",
    "        # Block 2\n",
    "        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "        bn2 = BatchNormalization()(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n",
    "        \n",
    "        # Block 3\n",
    "        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "        bn3 = BatchNormalization()(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n",
    "        \n",
    "        # Block 4\n",
    "        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "        bn4 = BatchNormalization()(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n",
    "        \n",
    "        # Bottleneck\n",
    "        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "        bn5 = BatchNormalization()(conv5)\n",
    "        \n",
    "        # Decoder\n",
    "        # Block 6\n",
    "        up6 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same', kernel_initializer='he_normal')(bn5)\n",
    "        merge6 = Concatenate(axis=3)([bn4, up6])\n",
    "        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "        bn6 = BatchNormalization()(conv6)\n",
    "        \n",
    "        # Block 7\n",
    "        up7 = Conv2DTranspose(256, 2, strides=(2, 2), padding='same', kernel_initializer='he_normal')(bn6)\n",
    "        merge7 = Concatenate(axis=3)([bn3, up7])\n",
    "        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "        bn7 = BatchNormalization()(conv7)\n",
    "        \n",
    "        # Block 8\n",
    "        up8 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same', kernel_initializer='he_normal')(bn7)\n",
    "        merge8 = Concatenate(axis=3)([bn2, up8])\n",
    "        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "        bn8 = BatchNormalization()(conv8)\n",
    "        \n",
    "        # Block 9\n",
    "        up9 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same', kernel_initializer='he_normal')(bn8)\n",
    "        merge9 = Concatenate(axis=3)([bn1, up9])\n",
    "        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "        bn9 = BatchNormalization()(conv9)\n",
    "        \n",
    "        # Output: softmax for multi-class (background + density classes)\n",
    "        outputs = Conv2D(self.n_classes, 1, activation='softmax')(bn9)\n",
    "        \n",
    "        model = Model(inputs=inputs, outputs=outputs, name='UnifiedSegmentationDensityUNet')\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=self.learning_rate),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def preprocess_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Preprocess image for model input\"\"\"\n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            if image.shape[2] == 1:\n",
    "                image = image[:, :, 0]\n",
    "            else:\n",
    "                image = np.mean(image, axis=2)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        if image.max() > 1.0:\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "        \n",
    "        # Resize if needed\n",
    "        if image.shape[:2] != self.input_shape[:2]:\n",
    "            from PIL import Image as PILImage\n",
    "            img_pil = PILImage.fromarray((image * 255).astype(np.uint8))\n",
    "            img_pil = img_pil.resize((self.input_shape[1], self.input_shape[0]))\n",
    "            image = np.array(img_pil).astype(np.float32) / 255.0\n",
    "        \n",
    "        # Add batch and channel dimensions\n",
    "        image = np.expand_dims(image, axis=0)  # (1, H, W)\n",
    "        image = np.expand_dims(image, axis=-1)  # (1, H, W, 1)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def process(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Process image: segment and classify densities in one forward pass\n",
    "        \n",
    "        Args:\n",
    "            image: Input image (H, W) or (H, W, C)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (signal_mask, density_classification)\n",
    "            - signal_mask: Binary mask (1 = signal, 0 = background)\n",
    "            - density_classification: Multi-class mask (0 = background, 1..n = density classes)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not built. Call build_model() first.\")\n",
    "        \n",
    "        # Preprocess\n",
    "        preprocessed = self.preprocess_image(image)\n",
    "        \n",
    "        # Predict\n",
    "        pred = self.model.predict(preprocessed, verbose=0)\n",
    "        \n",
    "        # Get class predictions (argmax)\n",
    "        classification = np.argmax(pred[0], axis=-1).astype(np.uint8)\n",
    "        \n",
    "        # Separate into signal mask and density classification\n",
    "        signal_mask = (classification > 0).astype(np.uint8)  # Any non-zero = signal\n",
    "        \n",
    "        # Density classification: 0 = background, 1..n = density classes\n",
    "        density_classification = classification.copy()\n",
    "        \n",
    "        return signal_mask, density_classification\n",
    "    \n",
    "    def load_model(self, model_path: str):\n",
    "        \"\"\"Load trained model from file\"\"\"\n",
    "        if not HAS_TF:\n",
    "            raise ImportError(\"TensorFlow required to load model\")\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.input_shape = self.model.input_shape[1:]  # Remove batch dimension\n",
    "        # Infer n_classes from output shape\n",
    "        self.n_classes = self.model.output_shape[-1]\n",
    "        self.n_density_classes = self.n_classes - 1\n",
    "\n",
    "    def train(self, train_images, train_masks, val_images=None, val_masks=None,\n",
    "              batch_size=8, epochs=50, model_save_path=None):\n",
    "        \"\"\"\n",
    "        Train the U-Net on multiple images.\n",
    "\n",
    "        Args:\n",
    "            train_images: np.ndarray of shape (N, H, W) or (N, H, W, C)\n",
    "            train_masks: np.ndarray of shape (N, H, W) with integer labels (0=background, 1..n)\n",
    "            val_images: optional validation images\n",
    "            val_masks: optional validation masks\n",
    "            batch_size: batch size for training\n",
    "            epochs: number of epochs\n",
    "            model_save_path: path to save best model\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not built. Call build_model() first.\")\n",
    "        \n",
    "        # Ensure 4D input: (N, H, W, 1)\n",
    "        def preprocess_dataset(images):\n",
    "            if len(images.shape) == 3:  # (N, H, W)\n",
    "                images = images[..., np.newaxis]\n",
    "            images = images.astype('float32') / 255.0\n",
    "            return images\n",
    "        \n",
    "        X_train = preprocess_dataset(train_images)\n",
    "        y_train = train_masks.astype('int32')\n",
    "        \n",
    "        if val_images is not None and val_masks is not None:\n",
    "            X_val = preprocess_dataset(val_images)\n",
    "            y_val = val_masks.astype('int32')\n",
    "            validation_data = (X_val, y_val)\n",
    "        else:\n",
    "            validation_data = None\n",
    "        \n",
    "        if not HAS_TF:\n",
    "            raise ImportError(\"TensorFlow required for training. Install with: pip install tensorflow\")\n",
    "        \n",
    "        callbacks = []\n",
    "        if model_save_path:\n",
    "            checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss',\n",
    "                                         save_best_only=True, verbose=1)\n",
    "            callbacks.append(checkpoint)\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "        callbacks.append(early_stop)\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=validation_data,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"UNIFIED SEGMENTATION & DENSITY CLASSIFICATION MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example: Create test image\n",
    "    \"\"\"test_image = np.ones((512, 512), dtype=np.uint8) * 200  # Bright background\n",
    "    test_image[200:300, 200:300] = 30   # Very dark (low density)\n",
    "    test_image[100:150, 400:450] = 50   # Medium dark (medium density)\n",
    "    test_image[350:400, 100:200] = 70   # Less dark (high density)\"\"\"\n",
    "    \n",
    "    # Initialize unified model\n",
    "    print(\"\\nInitializing unified model...\")\n",
    "    model = UnifiedSegmentationDensityModel(\n",
    "        seg_method='otsu',\n",
    "        density_method='percentile',\n",
    "        n_density_classes=3,\n",
    "        blur_size=5\n",
    "    )\n",
    "    \n",
    "   \"\"\" # Example 1: Process a single image (numpy array)\n",
    "    print(\"\\nExample 1: Processing numpy array...\")\n",
    "    test_image = np.ones((512, 512), dtype=np.uint8) * 200  # Bright background\n",
    "    test_image[200:300, 200:300] = 30   # Very dark (low density)\n",
    "    test_image[100:150, 400:450] = 50   # Medium dark (medium density)\n",
    "    test_image[350:400, 100:200] = 70   # Less dark (high density)\"\"\"\n",
    "    \n",
    "    signal_mask, density_class, stats = model.process_directory(test_image)\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Signal mask shape: {signal_mask.shape}\")\n",
    "    print(f\"  Density classification shape: {density_class.shape}\")\n",
    "    print(f\"  Signal pixels: {np.sum(signal_mask == 1)}\")\n",
    "    print(f\"  Density classes found: {np.unique(density_class)}\")\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  Thresholds: {stats['thresholds']}\")\n",
    "    for class_id, count in stats['class_counts'].items():\n",
    "        print(f\"  Class {class_id}: {count} pixels\")\n",
    "        if class_id in stats['class_intensities']:\n",
    "            int_stats = stats['class_intensities'][class_id]\n",
    "            print(f\"    Mean intensity: {int_stats['mean']:.1f} ± {int_stats['std']:.1f}\")\n",
    "    \n",
    "    # Example 2: Process directory of images\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Example 2: Processing Directory of Images\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nTo process a directory of images, use:\")\n",
    "    print(\"  model.process_directory('path/to/input/images/', 'path/to/output/')\")\n",
    "    print(\"\\nExample:\")\n",
    "    print(\"  model.process_directory('../testraw/', '../results/unified/')\")\n",
    "    print(\"\\nThis will:\")\n",
    "    print(\"  - Find all .tif/.tiff files in the input directory\")\n",
    "    print(\"  - Process each image\")\n",
    "    print(\"  - Save signal masks to: output_dir/signal_masks/\")\n",
    "    print(\"  - Save density classifications to: output_dir/density_classifications/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Usage Examples:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n1. Process numpy array:\")\n",
    "    print(\"   model = UnifiedSegmentationDensityModel(n_density_classes=3)\")\n",
    "    print(\"   signal_mask, density_class, stats = model.process(image)\")\n",
    "    print(\"\\n2. Process single image file:\")\n",
    "    print(\"   model.process_image('input.tif', 'signal.tif', 'density.tif', visualize=True)\")\n",
    "    print(\"\\n3. Process directory of images:\")\n",
    "    print(\"   # Process all .tif files in a directory\")\n",
    "    print(\"   model.process_directory('../testraw/', '../results/unified/')\")\n",
    "    print(\"   \")\n",
    "    print(\"   # Process only .png files\")\n",
    "    print(\"   model.process_directory('input/', 'output/', pattern='*.png')\")\n",
    "    print(\"   \")\n",
    "    print(\"   # Process with custom pattern\")\n",
    "    print(\"   model.process_directory('images/', 'results/', pattern='*.tiff')\")\n",
    "    print(\"\\n   Output structure:\")\n",
    "    print(\"   results/\")\n",
    "    print(\"   ├── signal_masks/          # Binary masks (1=signal, 0=background)\")\n",
    "    print(\"   │   ├── image1_signal.tif\")\n",
    "    print(\"   │   └── image2_signal.tif\")\n",
    "    print(\"   └── density_classifications/  # Multi-class masks (0=bg, 1-3=density)\")\n",
    "    print(\"       ├── image1_density.tif\")\n",
    "    print(\"       └── image2_density.tif\")\n",
    "    \n",
    "    if HAS_TF:\n",
    "        print(\"\\n  # Deep learning model (requires training)\")\n",
    "        print(\"  unet_model = UnifiedSegmentationDensityUNet(n_density_classes=3)\")\n",
    "        print(\"  unet_model.build_model()\")\n",
    "        print(\"  # Train model...\")\n",
    "        print(\"  signal_mask, density_class = unet_model.process(image)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9368d088-872d-46a0-8805-832bcbaf9797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
